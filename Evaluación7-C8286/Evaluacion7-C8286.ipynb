{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74507d49-cc1a-408d-88a3-21a195b983a5",
   "metadata": {},
   "source": [
    "### Concurrencia, paralelismo y procesamiento asíncronico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25a4eec-f23c-48d7-9584-f3a347ca0de1",
   "metadata": {},
   "source": [
    "### Parte 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ce52b9-b14e-4a33-93eb-5992186f34e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cliente\n",
    "import dill as pickle\n",
    "import socket\n",
    "from time import sleep\n",
    "\n",
    "def my_funs():\n",
    "    def mapper(v):\n",
    "        return v, 1\n",
    "\n",
    "    def reducer(my_args):\n",
    "        v, obs = my_args\n",
    "        return v, sum(obs)\n",
    "    return mapper, reducer\n",
    "\n",
    "def do_request(my_funs, data):\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = socket.create_connection(('127.0.0.1', 1936))\n",
    "        conn.send(b'\\x00')\n",
    "        my_code = pickle.dumps(my_funs.__code__)\n",
    "        conn.send(len(my_code).to_bytes(4, 'little', signed=False))\n",
    "        conn.send(my_code)\n",
    "        my_data = pickle.dumps(data)\n",
    "        conn.send(len(my_data).to_bytes(4, 'little'))\n",
    "        conn.send(my_data)\n",
    "        job_id = int.from_bytes(conn.recv(4), 'little')\n",
    "        print(f'Obteniendo datos desde job_id {job_id}')\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "\n",
    "    result = None\n",
    "    while result is None:\n",
    "        try:\n",
    "            conn = socket.create_connection(('127.0.0.1', 1936))\n",
    "            conn.send(b'\\x01')\n",
    "            conn.send(job_id.to_bytes(4, 'little'))\n",
    "            result_size = int.from_bytes(conn.recv(4), 'little')\n",
    "            result = pickle.loads(conn.recv(result_size))\n",
    "        finally:\n",
    "            if conn:\n",
    "                conn.close()\n",
    "        sleep(1)\n",
    "    print(f'El resultado es {result}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    do_request(my_funs, 'Python rocks. Python es lo maximo'.split(' '))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1270045-2c33-4fc4-9d3b-0927ec970c30",
   "metadata": {},
   "source": [
    "#### Explicación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "648c0229-f192-4698-a8be-fb8ae99e2683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill as pickle\n",
    "import socket\n",
    "from time import sleep\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8ab8da-25af-40ca-b1cf-08580538fb7e",
   "metadata": {},
   "source": [
    "Este bloque importa las librerías necesarias:\n",
    "\n",
    "- dill as pickle: dill es una extensión de la librería pickle que permite serializar objetos de Python más complejos. Se usa aquí para serializar y enviar funciones a través de una conexión de red.\n",
    "- socket: para la comunicación de red.\n",
    "- sleep: pausa la ejecución del programa para esperar por la respuesta del servidor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34cbd591-e11d-4010-ae5e-4ece456e8f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_funs():\n",
    "    def mapper(v):\n",
    "        return v, 1\n",
    "\n",
    "    def reducer(my_args):\n",
    "        v, obs = my_args\n",
    "        return v, sum(obs)\n",
    "    return mapper, reducer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fde9cf-7c11-4460-8ded-3857395b3d89",
   "metadata": {},
   "source": [
    "my_funs es una función que define y retorna dos funciones internas, mapper y reducer:\n",
    "\n",
    "- mapper: toma un valor v y retorna un par (v, 1).\n",
    "- reducer: toma un par (v, obs) donde obs es una lista, y retorna (v, sum(obs)), sumando todos los elementos en obs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c26a480-da3c-4b37-9347-55bed00dfbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_request(my_funs, data):\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = socket.create_connection(('127.0.0.1', 1936))\n",
    "        conn.send(b'\\x00')\n",
    "        ...\n",
    "        conn.send(my_code)\n",
    "        ...\n",
    "        conn.send(my_data)\n",
    "        job_id = int.from_bytes(conn.recv(4), 'little')\n",
    "        print(f'Obteniendo datos desde job_id {job_id}')\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "    ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154c3358-7e2d-49f6-9636-4a619e3d60af",
   "metadata": {},
   "source": [
    "do_request maneja la conexión de red y la solicitud al servidor:\n",
    "\n",
    "- Establece una conexión con el servidor en la dirección local (127.0.0.1) y puerto 1936.\n",
    "- Envía un byte inicial como indicador (posiblemente para indicar el tipo de solicitud).\n",
    "- Serializa y envía el código de las funciones (my_funs) y los datos.\n",
    "- Recibe un job_id del servidor, que es un identificador para la tarea solicitada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86e504b-ebea-4081-93ad-dfe3356937e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "    result = None\n",
    "    while result is None:\n",
    "        try:\n",
    "            conn = socket.create_connection(('127.0.0.1', 1936))\n",
    "            conn.send(b'\\x01')\n",
    "            conn.send(job_id.to_bytes(4, 'little'))\n",
    "            result_size = int.from_bytes(conn.recv(4), 'little')\n",
    "            result = pickle.loads(conn.recv(result_size))\n",
    "        finally:\n",
    "            if conn:\n",
    "                conn.close()\n",
    "        sleep(1)\n",
    "    print(f'El resultado es {result}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91100228-586b-4d43-9f4f-4cfcadba308b",
   "metadata": {},
   "source": [
    "Este bloque intenta obtener el resultado de la tarea:\n",
    "\n",
    "- Se reconecta al servidor y envía un nuevo byte indicador (posiblemente para solicitar el resultado).\n",
    "- Envía el job_id para identificar la tarea.\n",
    "- Recibe el resultado, deserializa y lo imprime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265488da-0314-468a-81c8-2cd621fffd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    do_request(my_funs, 'Python rocks. Python es lo maximo'.split(' '))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df632fd1-aee7-4c4c-b1b8-675e1d012d71",
   "metadata": {},
   "source": [
    "Si el script se ejecuta como programa principal, llama a do_request con las funciones definidas y un conjunto de datos de prueba que son palabras divididas de una frase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53468792-c458-4e8f-9f83-621bf20f2f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Servidor\n",
    "\n",
    "import asyncio\n",
    "#import marshal\n",
    "import pickle\n",
    "from random import randint\n",
    "# Codigo de Tiago Rodriguez\n",
    "import nest_asyncio\n",
    "\n",
    "# Aplicar nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "results = {}\n",
    "\n",
    "\n",
    "async def submit_job(reader, writer):\n",
    "    job_id = max(list(results.keys()) + [0]) + 1\n",
    "    writer.write(job_id.to_bytes(4, 'little'))\n",
    "    writer.close()\n",
    "    sleep_time = randint(1, 4)\n",
    "    await asyncio.sleep(sleep_time)\n",
    "    results[job_id] = sleep_time\n",
    "\n",
    "\n",
    "\n",
    "async def get_results(reader, writer):\n",
    "    job_id = int.from_bytes(await reader.read(4), 'little')\n",
    "    data = pickle.dumps(results.get(job_id, None))\n",
    "    writer.write(len(data).to_bytes(4, 'little'))\n",
    "    writer.write(data)\n",
    "\n",
    "\n",
    "async def accept_requests(reader, writer):\n",
    "    op = await reader.read(1)\n",
    "    if op[0] == 0:\n",
    "        await submit_job(reader, writer)\n",
    "    elif op[0] == 1:\n",
    "        await get_results(reader, writer)\n",
    "\n",
    "\n",
    "async def main():\n",
    "    server = await asyncio.start_server(accept_requests, '127.0.0.1', 1936)\n",
    "    async with server:\n",
    "        await server.serve_forever()\n",
    "\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd6a08d-9d2c-4429-93da-3f3138048f53",
   "metadata": {},
   "source": [
    "Este código implementa un servidor en Python utilizando asyncio que maneja solicitudes de tareas (jobs) y devuelve resultados asociados a esas tareas. Se relaciona directamente con el código anterior, actuando como el servidor al cual se conecta el cliente para enviar y recibir datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b4677c1-946b-471f-9a6f-33ca070977b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import pickle\n",
    "from random import randint\n",
    "import nest_asyncio\n",
    "\n",
    "# Aplicar nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "results = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d687693b-df8f-4550-9706-f190ab9f5392",
   "metadata": {},
   "source": [
    "- asyncio: Una biblioteca de Python para escribir código concurrente utilizando la sintaxis async/await.\n",
    "- pickle: Utilizado para serializar y deserializar objetos en Python.\n",
    "- randint: Genera números enteros aleatorios, usado aquí para simular un tiempo de procesamiento aleatorio.\n",
    "- results: Un diccionario para almacenar los resultados de las tareas, donde las claves son job_id y los valores son tiempos simulados de ejecución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dc67ab5-b67d-4a13-a6ab-2fd559fd28ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def submit_job(reader, writer):\n",
    "    job_id = max(list(results.keys()) + [0]) + 1\n",
    "    writer.write(job_id.to_bytes(4, 'little'))\n",
    "    writer.close()\n",
    "    sleep_time = randint(1, 4)\n",
    "    await asyncio.sleep(sleep_time)\n",
    "    results[job_id] = sleep_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3422b4-69cc-4d1e-8250-4fb1ee3e1944",
   "metadata": {},
   "source": [
    "submit_job es una función asíncrona que maneja la creación de nuevos trabajos:\n",
    "\n",
    "- Genera un job_id único incrementando el máximo job_id existente.\n",
    "- Envía este job_id al cliente.\n",
    "- Cierra el escritor para finalizar la transmisión.\n",
    "- Simula un tiempo de procesamiento aleatorio y almacena este tiempo en el diccionario results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cafcf53-75bc-4a5a-badc-9dba0b3157dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_results(reader, writer):\n",
    "    job_id = int.from_bytes(await reader.read(4), 'little')\n",
    "    data = pickle.dumps(results.get(job_id, None))\n",
    "    writer.write(len(data).to_bytes(4, 'little'))\n",
    "    writer.write(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab009678-a77e-444b-919a-d3b209c2401d",
   "metadata": {},
   "source": [
    "get_results recupera y envía los resultados de un trabajo específico:\n",
    "\n",
    "- Lee el job_id enviado por el cliente.\n",
    "- Obtiene el resultado asociado desde el diccionario results, lo serializa y lo envía de vuelta al cliente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef7358b0-1d76-452c-a9bf-d512d2ba0fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def accept_requests(reader, writer):\n",
    "    op = await reader.read(1)\n",
    "    if op[0] == 0:\n",
    "        await submit_job(reader, writer)\n",
    "    elif op[0] == 1:\n",
    "        await get_results(reader, writer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f795a19d-b799-491d-9cf2-c76e65cc0e83",
   "metadata": {},
   "source": [
    "accept_requests determina el tipo de solicitud basada en un byte inicial y llama a la función correspondiente para manejar la solicitud:\n",
    "\n",
    "- 0 para una nueva tarea.\n",
    "- 1 para recuperar los resultados de una tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d81fac2-ff15-46c5-ba3b-751e54422eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    server = await asyncio.start_server(accept_requests, '127.0.0.1', 1936)\n",
    "    async with server:\n",
    "        await server.serve_forever()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d71139-54e8-47c1-a853-d07855e76309",
   "metadata": {},
   "source": [
    "main inicia el servidor en la dirección 127.0.0.1 y puerto 1936, y lo mantiene corriendo indefinidamente para manejar solicitudes entrantes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c53c60f8-913c-48cb-a218-4c86534a536d",
   "metadata": {},
   "outputs": [],
   "source": [
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64896d84-1171-49c3-860d-ecda058300c2",
   "metadata": {},
   "source": [
    "Inicia la ejecución del servidor usando el event loop de asyncio.\n",
    "\n",
    "Este servidor es esencialmente el lado del servidor para el código del cliente presentado anteriormente. Juntos, implementan un sistema básico donde el cliente envía datos y funciones para ser ejecutadas, y el servidor maneja esas solicitudes, realiza cálculos (simulados aquí como tiempos de espera), y devuelve los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80f3b809-9e3f-48e2-bdbd-0e083d1c8487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<coroutine object wait at 0x0000018D5D499140>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### sleep.py\n",
    "\n",
    "import asyncio\n",
    "\n",
    "async def lazy_printer(delay, message):\n",
    "    await asyncio.sleep(delay)\n",
    "    print(message)\n",
    "\n",
    "asyncio.wait([lazy_printer(1, 'Lento'), lazy_printer(0, 'Full velocidad')])\n",
    "#asyncio.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2518f5a6-2885-47db-81fd-fbe83878fd35",
   "metadata": {},
   "source": [
    "El código ilustra un ejemplo simple de uso de asyncio, una biblioteca en Python diseñada para manejar la ejecución concurrente de código usando corutinas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b62f47f-6159-46d2-a0be-809c4f538fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def lazy_printer(delay, message):\n",
    "    await asyncio.sleep(delay)\n",
    "    print(message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a889ea7-de9c-4880-b1cc-8340c0a0fb80",
   "metadata": {},
   "source": [
    "lazy_printer es una función asíncrona que recibe dos argumentos: delay y message. La función pausa su ejecución por el número de segundos especificado por delay (esto simula un trabajo que tarda un cierto tiempo en completarse) y luego imprime el message dado. await asyncio.sleep(delay) es crucial aquí porque le permite a otras corutinas ejecutarse mientras lazy_printer está en espera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f64d1745-7c61-451c-90cd-959f42b5f9c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<coroutine object wait at 0x0000018D5D499740>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asyncio.wait([lazy_printer(1, 'Lento'), lazy_printer(0, 'Full velocidad')])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63081cb-e8fa-4083-801b-6f07b759de81",
   "metadata": {},
   "source": [
    "Aquí se usa asyncio.wait, una función que espera a que las corutinas especificadas en el iterable (en este caso, dos llamadas a lazy_printer) terminen. asyncio.wait no inicia la ejecución de las corutinas por sí misma, solo las organiza para que se ejecuten cuando el bucle de eventos de asyncio esté corriendo.\n",
    "\n",
    "Una aclaración importante es que asyncio.wait retorna dos conjuntos de Tasks (un tipo de objeto Future en asyncio que encapsula la ejecución de una corutina): uno para las tareas que se completaron y otro para las que no se completaron. En este contexto, el código no se está ejecutando realmente porque no hay un bucle de eventos corriendo las corutinas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a91dc10-67bd-44b9-91b6-a0a8d6f72127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# asyncio.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87e0ef4-2869-402b-8c5f-d949749d4622",
   "metadata": {},
   "source": [
    "asyncio.run() es una función que se utiliza para ejecutar la corutina principal y todas las corutinas que se lanzan desde ella. Es la forma recomendada de ejecutar código asyncio completo. asyncio.run() toma una corutina como argumento, inicia un nuevo bucle de eventos, corre la corutina, y finaliza el bucle de eventos una vez que la corutina termina.\n",
    "\n",
    "Sin embargo, este código específicamente no está completo porque no está envuelto dentro de asyncio.run(). Un uso adecuado para ejecutar las tareas concurrentemente sería algo así:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a097482d-3013-4b3f-9cd2-436be677544b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_21676\\4120369814.py:2: DeprecationWarning: The explicit passing of coroutine objects to asyncio.wait() is deprecated since Python 3.8, and scheduled for removal in Python 3.11.\n",
      "  await asyncio.wait([\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full velocidad\n",
      "Lento\n"
     ]
    }
   ],
   "source": [
    "async def main():\n",
    "    await asyncio.wait([\n",
    "        lazy_printer(1, 'Lento'),\n",
    "        lazy_printer(0, 'Full velocidad')\n",
    "    ])\n",
    "\n",
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150b68f4-a75e-4428-a384-361c590d0d29",
   "metadata": {},
   "source": [
    "Aquí, main() es la corutina que espera a que se complete el asyncio.wait, y asyncio.run(main()) arranca el bucle de eventos y ejecuta main() hasta su finalización."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003bc045",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4652d502-6a8c-456a-996d-eb5205bbe348",
   "metadata": {},
   "source": [
    "#### Ejercicio 1: Extendiendo la funcionalidad del servidor\n",
    "Basado en el código del servidor que utiliza asyncio para gestionar trabajos, extiende el servidor para realizar tareas más complejas. Añade una función que pueda procesar una lista de números y devolver su suma. Deberás modificar tanto el código del servidor como el del cliente para manejar esta nueva funcionalidad.\n",
    "\n",
    "Pasos:\n",
    "\n",
    "- Define una nueva función en el cliente para enviar una lista de números al servidor.\n",
    "- En el servidor, añade una corutina que reciba esta lista, calcule la suma y almacene el resultado en el diccionario results.\n",
    "- Asegúrate de que el cliente pueda solicitar y recibir el resultado de esta suma.\n",
    "\n",
    "#### Ejercicio 2: Manejo de múltiples clientes\n",
    "Modifica el servidor basado en asyncio para que pueda manejar múltiples clientes simultáneamente. Cada cliente debería ser capaz de enviar múltiples solicitudes sin esperar que las anteriores se completen.\n",
    "\n",
    "Pasos:\n",
    "\n",
    "- Modifica el código del servidor para que pueda manejar distintas solicitudes de múltiples clientes de forma asíncrona.\n",
    "- Asegúrate de que el servidor pueda gestionar y mantener el estado de cada cliente por separado.\n",
    "- Prueba la capacidad del servidor conectando varios clientes al mismo tiempo y realizando diferentes solicitudes.\n",
    "\n",
    "#### Ejercicio 3: Simulación de tareas de larga duración\n",
    "Utilizando el ejemplo de lazy_printer, crea un simulador para tareas de larga duración que afecten la respuesta del servidor basado en la complejidad de la tarea.\n",
    "\n",
    "Pasos:\n",
    "\n",
    "- Define varias corutinas que simulen diferentes tiempos y complejidades de tareas (por ejemplo, cálculos matemáticos complejos o procesamiento de texto).\n",
    "- Utiliza asyncio.wait para manejar estas tareas de forma concurrente en el cliente y envía estas tareas al servidor.\n",
    "- Añade lógica en el servidor para responder a estas tareas con diferentes tiempos de espera basados en su complejidad.\n",
    "\n",
    "#### Ejercicio 4: Mejorando la eficiencia con paralelismo\n",
    "\n",
    "Investiga cómo asyncio puede integrarse con bibliotecas de procesamiento en paralelo como concurrent.futures para mejorar la eficiencia del servidor al manejar tareas que son intensivas en CPU.\n",
    "\n",
    "Pasos:\n",
    "\n",
    "- Modifica el servidor para utilizar concurrent.futures.ProcessPoolExecutor para ejecutar cálculos intensivos en paralelo.\n",
    "- Crea tareas que requieran intensivo uso de CPU y envíalas al servidor.\n",
    "- Observa y compara el rendimiento cuando se usan corutinas simples versus la ejecución en paralelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476ad94b",
   "metadata": {},
   "source": [
    "## Ejercicio1\n",
    "\n",
    "#### Ejercicio 1: Extendiendo la funcionalidad del servidor\n",
    "Basado en el código del servidor que utiliza asyncio para gestionar trabajos, extiende el servidor para realizar tareas más complejas. Añade una función que pueda procesar una lista de números y devolver su suma. Deberás modificar tanto el código del servidor como el del cliente para manejar esta nueva funcionalidad.\n",
    "\n",
    "Pasos:\n",
    "\n",
    "- Define una nueva función en el cliente para enviar una lista de números al servidor.\n",
    "- En el servidor, añade una corutina que reciba esta lista, calcule la suma y almacene el resultado en el diccionario results.\n",
    "- Asegúrate de que el cliente pueda solicitar y recibir el resultado de esta suma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f934c9-a437-4979-a90a-9f41662e6afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Respuestas\n",
    "# Cliente\n",
    "import dill as pickle\n",
    "import socket\n",
    "from time import sleep\n",
    "\n",
    "def numero_list(numbers):\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = socket.create_connection(('127.0.0.1', 1936))\n",
    "        conn.send(b'\\x00')  \n",
    "        numbers_data = pickle.dumps(numbers)\n",
    "        conn.send(len(numbers_data).to_bytes(4, 'little'))\n",
    "        conn.send(numbers_data)\n",
    "        job_id = int.from_bytes(conn.recv(4), 'little')\n",
    "        print(f'Enviada lista de números al servidor. job_id: {job_id}')\n",
    "        return job_id\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "\n",
    "def resultado(job_id):\n",
    "    result = None\n",
    "    while result is None:\n",
    "        try:\n",
    "            conn = socket.create_connection(('127.0.0.1', 1936))\n",
    "            conn.send(b'\\x01')\n",
    "            conn.send(job_id.to_bytes(4, 'little'))\n",
    "            result_size = int.from_bytes(conn.recv(4), 'little')\n",
    "            result = pickle.loads(conn.recv(result_size))\n",
    "        finally:\n",
    "            if conn:\n",
    "                conn.close()\n",
    "        sleep(1)\n",
    "    print(f'El resultado de la suma es: {result}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    numbers = [1, 2, 3, 4, 5]  \n",
    "    job_id = numero_list(numbers)\n",
    "    if job_id:\n",
    "        resultado(job_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9d61c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Servidor\n",
    "\n",
    "import asyncio\n",
    "import pickle\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "results = {}\n",
    "\n",
    "async def submit_job(reader, writer):\n",
    "    job_id = max(list(results.keys()) + [0]) + 1\n",
    "    writer.write(job_id.to_bytes(4, 'little'))\n",
    "    await writer.drain()\n",
    "    data_length = int.from_bytes(await reader.read(4), 'little')\n",
    "    data = pickle.loads(await reader.read(data_length))\n",
    "    results[job_id] = sum(data)\n",
    "\n",
    "async def get_results(reader, writer):\n",
    "    job_id = int.from_bytes(await reader.read(4), 'little')\n",
    "    result = results.get(job_id)\n",
    "    if result is not None:\n",
    "        result_data = pickle.dumps(result)\n",
    "        writer.write(len(result_data).to_bytes(4, 'little'))\n",
    "        writer.write(result_data)\n",
    "    else:\n",
    "        writer.write((0).to_bytes(4, 'little'))\n",
    "    await writer.drain()\n",
    "\n",
    "async def accept_requests(reader, writer):\n",
    "    op = await reader.read(1)\n",
    "    if op[0] == 0:  # Recibir lista de números y calcular suma\n",
    "        await submit_job(reader, writer)\n",
    "    elif op[0] == 1:  # Recibir resultado\n",
    "        await get_results(reader, writer)\n",
    "\n",
    "async def main():\n",
    "    server = await asyncio.start_server(accept_requests, '127.0.0.1', 1936)\n",
    "    async with server:\n",
    "        await server.serve_forever()\n",
    "\n",
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08e0ce4",
   "metadata": {},
   "source": [
    "#### Ejercicio 2: Manejo de múltiples clientes\n",
    "Modifica el servidor basado en asyncio para que pueda manejar múltiples clientes simultáneamente. Cada cliente debería ser capaz de enviar múltiples solicitudes sin esperar que las anteriores se completen.\n",
    "\n",
    "Pasos:\n",
    "\n",
    "- Modifica el código del servidor para que pueda manejar distintas solicitudes de múltiples clientes de forma asíncrona.\n",
    "- Asegúrate de que el servidor pueda gestionar y mantener el estado de cada cliente por separado.\n",
    "- Prueba la capacidad del servidor conectando varios clientes al mismo tiempo y realizando diferentes solicitudes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb02910-a51b-435d-a217-d22e3b00b121",
   "metadata": {},
   "source": [
    "### Parte 2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d0ebbd0-6470-4aea-a3fc-cdb2069062b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Python', 2), ('es', 1), ('lo', 1), ('mejor', 1), ('rocks', 1)]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "# Codigo de Thiago Rodriguez\n",
    "\n",
    "def map_reduce_ultra_naive(my_input, mapper, reducer):\n",
    "    map_results = map(mapper, my_input)\n",
    "\n",
    "    distributor = defaultdict(list)\n",
    "    for key, value in map_results:\n",
    "        distributor[key].append(value)\n",
    "\n",
    "    return map(reducer, distributor.items())\n",
    "\n",
    "\n",
    "words = 'Python es lo mejor Python rocks'.split(' ')\n",
    "\n",
    "emiter = lambda word: (word, 1)\n",
    "counter = lambda emitted: (emitted[0], sum(emitted[1]))\n",
    "\n",
    "\n",
    "a = list(map_reduce_ultra_naive(words, emiter, counter))\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b75d13c-11ff-46c8-b67d-98db073d16b3",
   "metadata": {},
   "source": [
    "El código que proporcionaste implementa una versión muy simplificada del patrón de diseño \"MapReduce\", comúnmente utilizado para procesar y generar grandes conjuntos de datos con un modelo distribuido de computación en paralelo. Aquí, el código no necesita un cliente ni operaciones de sleep porque es una implementación completamente sincrónica y local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "522a0169-ca8e-4678-b266-9b129c10d5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530b62c6-5f8d-404f-ad52-b1216d8b4fc3",
   "metadata": {},
   "source": [
    "Esta importación trae defaultdict desde el módulo collections. defaultdict es una subclase de dict que proporciona un valor predeterminado para la clave que no existe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bb2a156-fa0e-41e7-8f54-e084f5694fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_reduce_ultra_naive(my_input, mapper, reducer):\n",
    "    map_results = map(mapper, my_input)\n",
    "\n",
    "    distributor = defaultdict(list)\n",
    "    for key, value in map_results:\n",
    "        distributor[key].append(value)\n",
    "\n",
    "    return map(reducer, distributor.items())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc86779f-3ed7-4f77-a330-497cbbee8b1b",
   "metadata": {},
   "source": [
    "La función map_reduce_ultra_naive toma tres argumentos: my_input (datos de entrada), mapper (función de mapeo) y reducer (función de reducción).\n",
    "\n",
    "- Mapeo: map(mapper, my_input) aplica la función mapper a cada elemento en my_input, generando una lista de tuplas (clave, valor).\n",
    "- Distribución: Se utiliza defaultdict para agrupar todos los valores asociados con la misma clave en una lista. Esto es necesario para la etapa de reducción.\n",
    "- Reducción: map(reducer, distributor.items()) aplica la función reducer a cada par (clave, lista de valores) en el distributor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "483c29f1-4a35-463b-8e83-7aaf4292b4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = 'Python es lo mejor Python rocks'.split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbbbc71-4a17-4ff5-aa81-28334a80d862",
   "metadata": {},
   "source": [
    "Esta línea divide la cadena en una lista de palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9eed863-e1ea-457a-9e0f-85a0ebdc38d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "emiter = lambda word: (word, 1)\n",
    "counter = lambda emitted: (emitted[0], sum(emitted[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60759227-bfde-4479-a2ca-ae8861b092ea",
   "metadata": {},
   "source": [
    "- emiter: Una función lambda que toma una palabra y devuelve una tupla con la palabra y el número 1. Esta es la función de mapeo que prepara los datos para la reducción.\n",
    "- counter: Una función lambda que toma una tupla (palabra, lista de unos) y devuelve una tupla con la palabra y la suma de los unos, efectivamente contando cuántas veces aparece cada palabra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7a21924-57da-4e54-94bf-f18a0edf79a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(map_reduce_ultra_naive(words, emiter, counter))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dd196f-162e-4295-9460-5f4ab509bf81",
   "metadata": {},
   "source": [
    "Esta línea aplica la función map_reduce_ultra_naive a la lista de palabras con las funciones emiter y counter especificadas, y luego convierte el resultado (que es un iterador) en una lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03343468-5441-4010-9f10-d3ec810a7019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Python', 2), ('es', 1), ('lo', 1), ('mejor', 1), ('rocks', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54df1373-d9ec-4843-882b-dd7a646b157c",
   "metadata": {},
   "source": [
    "Imprime el resultado final, que sería una lista de tuplas, cada una mostrando una palabra y su frecuencia en la entrada original."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973a99e5-f09b-4e9e-8069-4bdec9b9d6bf",
   "metadata": {},
   "source": [
    "#### Ejercicio 1: Paralelización del proceso de MapReduce\n",
    "\n",
    "Modifica el código para usar múltiples hilos o procesos que ejecuten las funciones de mapeo y reducción de manera paralela. Esto simula cómo funcionaría un entorno de MapReduce distribuido a pequeña escala.\n",
    "\n",
    "Pasos:\n",
    "\n",
    "- Utiliza concurrent.futures.ThreadPoolExecutor o concurrent.futures.ProcessPoolExecutor para paralelizar la función de mapeo.\n",
    "- Implementa la reducción de manera que pueda manejar la entrada de múltiples hilos/procesos de manera sincronizada.\n",
    "- Compara el rendimiento del enfoque paralelo con el enfoque sincrónico original.\n",
    "\n",
    "#### Ejercicio 2: MapReduce distribuido\n",
    "\n",
    "Crea una simulación de un entorno de MapReduce distribuido donde múltiples clientes pueden enviar sus datos a un servidor que coordina las tareas de mapeo y reducción.\n",
    "\n",
    "Pasos:\n",
    "\n",
    "- Desarrolla un servidor que pueda recibir datos de múltiples clientes y asignar tareas de mapeo a diferentes nodos (simulados por hilos o procesos).\n",
    "- Los resultados del mapeo deben ser enviados de vuelta al servidor, que luego ejecutará la reducción.\n",
    "- Evalúa cómo la distribución afecta la eficiencia y el tiempo de procesamiento total.\n",
    "\n",
    "#### Ejercicio 3: Balanceo de carga en MapReduce\n",
    "Implementa un mecanismo de balanceo de carga para optimizar la distribución de tareas de mapeo entre varios nodos de procesamiento.\n",
    "\n",
    "Pasos:\n",
    "\n",
    "- Diseña una función que determine cómo se distribuyen los datos entrantes entre los nodos de mapeo basados en su carga actual o capacidad.\n",
    "- Implementa la lógica para que el nodo de reducción pueda esperar y combinar resultados de todos los nodos de mapeo antes de proceder.\n",
    "- Analiza el impacto del balanceo de carga en la eficiencia del sistema.\n",
    "\n",
    "#### Ejercicio 4: Tolerancia a fallos en MapReduce\n",
    "Añade tolerancia a fallos al sistema MapReduce, permitiendo que el sistema se recupere de errores en los nodos de mapeo o reducción.\n",
    "\n",
    "Pasos:\n",
    "\n",
    "- Implementa una funcionalidad que detecte fallos en nodos y reasigne sus tareas a otros nodos disponibles.\n",
    "- Asegúrate de que los datos necesarios para reasignar tareas estén disponibles, quizás usando replicación.\n",
    "- Testea el sistema con fallos simulados y evalúa cómo afecta la robustez y el rendimiento del sistema.\n",
    "\n",
    "#### Ejercicio 5: Optimización de reducción en MapReduce\n",
    "Optimiza el paso de reducción para manejar grandes volúmenes de datos más eficientemente.\n",
    "\n",
    "Pasos:\n",
    "\n",
    "- Implementa una estrategia de \"combiner\" local en cada nodo de mapeo para reducir los datos antes de enviarlos al nodo de reducción.\n",
    "- Asegúrate de que la función de reducción pueda manejar la entrada pre-reducida eficientemente.\n",
    "- Evalúa cómo esta optimización afecta la carga de red y el tiempo de procesamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142d2ba5",
   "metadata": {},
   "source": [
    "#### Ejercicio 1: Paralelización del proceso de MapReduce\n",
    "\n",
    "Modifica el código para usar múltiples hilos o procesos que ejecuten las funciones de mapeo y reducción de manera paralela. Esto simula cómo funcionaría un entorno de MapReduce distribuido a pequeña escala.\n",
    "\n",
    "Pasos:\n",
    "\n",
    "- Utiliza concurrent.futures.ThreadPoolExecutor o concurrent.futures.ProcessPoolExecutor para paralelizar la función de mapeo.\n",
    "- Implementa la reducción de manera que pueda manejar la entrada de múltiples hilos/procesos de manera sincronizada.\n",
    "- Compara el rendimiento del enfoque paralelo con el enfoque sincrónico original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e71e32dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paralelo: [('Python', 2), ('es', 1), ('lo', 1), ('mejor', 1), ('rocks', 1)]\n",
      " En 0.0010 segundos\n",
      "sincronico: [('Python', 2), ('es', 1), ('lo', 1), ('mejor', 1), ('rocks', 1)]\n",
      " En 0.0000 segundos\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures \n",
    "from collections import defaultdict\n",
    "import time\n",
    "def emiter(word):\n",
    "    return word, 1\n",
    "\n",
    "\n",
    "def counter(emitted):\n",
    "    return emitted[0], sum(emitted[1])\n",
    "\n",
    "def map_reduce_ultra_naive(my_input, mapper, reducer):\n",
    "    map_results = map(mapper, my_input)\n",
    "\n",
    "    distributor = defaultdict(list)\n",
    "    for key, value in map_results:\n",
    "        distributor[key].append(value)\n",
    "\n",
    "    return map(reducer, distributor.items())\n",
    "\n",
    "def map_reduce_ultra_naive_parallel(my_input, mapper, reducer):\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "         map_results = list(executor.map(mapper, my_input))\n",
    "         distributor = defaultdict(list)\n",
    "         for key, value in map_results:\n",
    "            distributor[key].append(value)\n",
    "    \n",
    "         reduce=list(executor.map(reducer, distributor.items()))\n",
    "    return reduce\n",
    "\n",
    "def main():\n",
    "    words = 'Python es lo mejor Python rocks'.split(' ')\n",
    "    \n",
    "\n",
    "    start_time = time.time()\n",
    "    a = list(map_reduce_ultra_naive_parallel(words, emiter, counter))\n",
    "    sync_duration = time.time() - start_time\n",
    "    print(\"Paralelo:\",a)\n",
    "    print(f\" En {sync_duration:.4f} segundos\")\n",
    "    \n",
    "    start_time1 = time.time()\n",
    "    a = list(map_reduce_ultra_naive(words, emiter, counter))\n",
    "    sync_duration1 = time.time() - start_time1\n",
    "    print(\"sincronico:\",a)\n",
    "    print(f\" En {sync_duration1:.4f} segundos\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3bdf64-94b7-4161-bce7-cf4f738eb269",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399e9f62-e320-40b1-b168-eec0779ce343",
   "metadata": {},
   "source": [
    "### Parte 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a9dc7b-7c7b-4cb2-8c45-290b22cfa15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from concurrent.futures import ThreadPoolExecutor as Executor\n",
    "# Codigo de Tiago Rodriguez\n",
    "\n",
    "def map_reduce_still_naive(my_input, mapper, reducer):\n",
    "    with Executor() as executor:\n",
    "        map_results = executor.map(mapper, my_input)\n",
    "\n",
    "        distributor = defaultdict(list)\n",
    "        for key, value in map_results:\n",
    "            distributor[key].append(value)\n",
    "        results = executor.map(reducer, distributor.items())\n",
    "    return results\n",
    "\n",
    "\n",
    "words = filter(lambda x: x!= '', map(lambda x: x.strip().rstrip(), ' '.join(open('texto.txt', 'rt', encoding='utf-8').readlines()).split(' ')))\n",
    "\n",
    "emiter = lambda word: (word, 1)\n",
    "counter = lambda emitted: (emitted[0], sum(emitted[1]))\n",
    "\n",
    "a = list(map_reduce_still_naive(words, emiter, counter))\n",
    "\n",
    "for i in sorted(a, key=lambda x: x[1]):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cc1929-4617-426d-80dc-2468773015cc",
   "metadata": {},
   "source": [
    "Este código es una implementación más avanzada de la técnica de MapReduce, utilizando la concurrencia para paralelizar tanto la fase de mapeo como la de reducción. Hace uso del módulo concurrent.futures, específicamente ThreadPoolExecutor, para manejar la ejecución paralela de las funciones de mapeo y reducción. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4add727-144f-4b8e-bf4c-a8dfd7c1d4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from concurrent.futures import ThreadPoolExecutor as Executor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e40bb3-e68f-41a0-aa0f-1be050864c84",
   "metadata": {},
   "source": [
    "- defaultdict: Una subclase de diccionario que proporciona un valor predeterminado para claves que no están en el diccionario.\n",
    "- ThreadPoolExecutor: Una clase para ejecutar llamadas de función de manera asincrónica usando un pool de hilos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1c6ed3-2a69-40e1-a055-47c1be2c2634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_reduce_still_naive(my_input, mapper, reducer):\n",
    "    with Executor() as executor:\n",
    "        map_results = executor.map(mapper, my_input)\n",
    "\n",
    "        distributor = defaultdict(list)\n",
    "        for key, value in map_results:\n",
    "            distributor[key].append(value)\n",
    "        results = executor.map(reducer, distributor.items())\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de366ba-fd79-4063-b5d5-cfead80a0a60",
   "metadata": {},
   "source": [
    "- map_reduce_still_naive: Una función que toma una entrada my_input, una función mapper y una función reducer. Utiliza un ThreadPoolExecutor para ejecutar las funciones mapper y reducer.\n",
    "- executor.map(mapper, my_input): Paraleliza la aplicación de la función mapper a cada elemento de my_input.\n",
    "- distributor: Un defaultdict que agrupa los valores asociados con cada clave producida por la función mapper.\n",
    "- executor.map(reducer, distributor.items()): Aplica la función reducer a cada grupo de valores (de manera paralela), procesando los elementos que comparten la misma clave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3eff7f6-25e0-456e-bbd3-1b6d3fbc605b",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = filter(lambda x: x!= '', map(lambda x: x.strip().rstrip(), ' '.join(open('texto.txt', 'rt', encoding='utf-8').readlines()).split(' ')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0327096-e922-43c6-9a80-4237ef8deb83",
   "metadata": {},
   "source": [
    "* Esta línea prepara words leyendo un archivo texto.txt, dividiendo el contenido en palabras, quitando los espacios en blanco innecesarios y filtrando cualquier string vacío. Este será el input para la función map_reduce_still_naive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adce8b1c-908d-4b73-8c1c-118fb1cbfd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "emiter = lambda word: (word, 1)\n",
    "counter = lambda emitted: (emitted[0], sum(emitted[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5fdf26-60c3-46e5-bde3-4f85b33c8b04",
   "metadata": {},
   "source": [
    "* emiter: Una función mapper que toma una palabra y devuelve un par (palabra, 1).\n",
    "* counter: Una función reducer que toma un par (palabra, lista de unos) y devuelve (palabra, total), sumando todos los unos para contar cuántas veces aparece cada palabra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104cd7a9-41fc-453b-8cb2-e9d783cae902",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(map_reduce_still_naive(words, emiter, counter))\n",
    "for i in sorted(a, key=lambda x: x[1]):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dd1231-9e09-4552-a200-537101812b15",
   "metadata": {},
   "source": [
    "- list(map_reduce_still_naive(words, emiter, counter)): Ejecuta el proceso de MapReduce y convierte los resultados (un iterable de tuplas) en una lista.\n",
    "- sorted(a, key=lambda x: x[1]): Ordena los resultados basado en la frecuencia de cada palabra (el segundo elemento de cada tupla).\n",
    "- El bucle for imprime cada palabra junto con su frecuencia, ordenadas por frecuencia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9587198a-63aa-4a20-bdb7-86335bd5b402",
   "metadata": {},
   "source": [
    "Los resultados dependerán del contenido del archivo texto.txt, pero en general, la salida mostrará cada palabra que aparece en el texto junto con el número de veces que aparece, ordenadas por su frecuencia. Este proceso se realiza de manera eficiente utilizando múltiples hilos para acelerar tanto el mapeo como la reducción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d28032-330a-46ef-9eb1-64f8b4533f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from concurrent.futures import ThreadPoolExecutor as Executor\n",
    "from time import sleep\n",
    "\n",
    "# Codigo de Tiago Rodriguez\n",
    "\n",
    "def report_progress(futures, tag, callback):\n",
    "    not_done = 1\n",
    "    done = 0\n",
    "    while not_done > 0:\n",
    "        not_done = 0\n",
    "        done = 0\n",
    "        for fut in futures:\n",
    "            if fut.done():\n",
    "                done +=1\n",
    "            else:\n",
    "                not_done += 1\n",
    "        sleep(0.5)\n",
    "        if not_done > 0 and callback:\n",
    "            callback(tag, done, not_done)\n",
    "    \n",
    "\n",
    "def async_map(executor, mapper, data):\n",
    "    futures = []\n",
    "    for datum in data:\n",
    "        futures.append(executor.submit(mapper, datum))\n",
    "    return futures\n",
    "\n",
    "\n",
    "def map_less_naive(executor, my_input, mapper):\n",
    "    map_results = async_map(executor, mapper, my_input)\n",
    "    return map_results\n",
    "\n",
    "\n",
    "def map_reduce_less_naive(my_input, mapper, reducer, callback=None):\n",
    "    with Executor(max_workers=2) as executor:\n",
    "        futures = async_map(executor, mapper, my_input)\n",
    "        report_progress(futures, 'map', callback)\n",
    "        #wait(futures).done\n",
    "        map_results = map(lambda f: f.result(), futures)\n",
    "        distributor = defaultdict(list)\n",
    "        for key, value in map_results:\n",
    "            distributor[key].append(value)\n",
    "\n",
    "        futures = async_map(executor, reducer, distributor.items())\n",
    "        report_progress(futures, 'reduce', callback)\n",
    "        #wait(futures).done\n",
    "        results = map(lambda f: f.result(), futures)\n",
    "    return results\n",
    "\n",
    "\n",
    "words = filter(lambda x: x!= '', map(lambda x: x.strip().rstrip(), ' '.join(open('texto.txt', 'rt', encoding='utf-8').readlines()).split(' ')))\n",
    "\n",
    "def emitter(word):\n",
    "    #sleep(10)\n",
    "    return word, 1\n",
    "\n",
    "\n",
    "counter = lambda emitted: (emitted[0], sum(emitted[1]))\n",
    "\n",
    "def reporter(tag, done, not_done):\n",
    "    print(f'Operacion {tag}: {done}/{done+not_done}')\n",
    "\n",
    "words = 'Python es super,  Python rocks'.split(' ')\n",
    "a = map_reduce_less_naive(words, emitter, counter, reporter)\n",
    "\n",
    "for i in sorted(a, key=lambda x: x[1]):\n",
    "    print(i)\n",
    "\n",
    "#words = 'Python es super Python rocks'.split(' ')\n",
    "\n",
    "#with Executor(max_workers=4) as executor:\n",
    "#    maps = map_less_naive(executor, words, emitter)\n",
    "#    print(maps[-1])\n",
    "#    not_done = 1\n",
    "#    while not_done > 0:\n",
    "#        not_done = 0\n",
    "#        for fut in maps:\n",
    "#            not_done += 1 if not fut.done() else 0\n",
    "#        sleep(1)\n",
    "#        print(f'Aun no ha finalizado: {not_done}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cb0e28-eede-403b-945c-00de4d4b3382",
   "metadata": {},
   "source": [
    "El código proporcionado es una versión más sofisticada del patrón de diseño MapReduce, la cual implementa funcionalidades adicionales de manejo de concurrencia utilizando ThreadPoolExecutor de concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dbcf0b-0758-4742-b410-ec9ef2d0ae47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from concurrent.futures import ThreadPoolExecutor as Executor\n",
    "from time import sleep\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f063f26a-e784-49fb-8151-0fdd07e8e0e0",
   "metadata": {},
   "source": [
    "- defaultdict: Facilita el agrupamiento de resultados.\n",
    "- Executor: Se utiliza para la ejecución concurrente.\n",
    "- sleep: Utilizado aquí para pausas durante la monitorización del progreso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5551b5-db13-4854-bd60-39ce86c158eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_progress(futures, tag, callback):\n",
    "    # Inicializa 'not_done' para entrar en el bucle while.\n",
    "    not_done = 1\n",
    "    \n",
    "    # Bucle que se ejecuta mientras haya tareas sin finalizar.\n",
    "    while not_done > 0:\n",
    "        # Reinicia los contadores en cada iteración del bucle.\n",
    "        not_done = 0\n",
    "        done = 0\n",
    "        \n",
    "        # Itera sobre cada futuro en la lista de 'futures'.\n",
    "        for fut in futures:\n",
    "            # Comprueba si el futuro ha terminado y actualiza los contadores correspondientes.\n",
    "            if fut.done():\n",
    "                done += 1  # Aumenta el contador de tareas completadas.\n",
    "            else:\n",
    "                not_done += 1  # Aumenta el contador de tareas no completadas.\n",
    "        \n",
    "        # Pausa de medio segundo para no saturar con demasiadas comprobaciones.\n",
    "        sleep(0.5)\n",
    "        \n",
    "        # Si hay tareas sin completar y se ha proporcionado una función de callback,\n",
    "        # llama al callback con la etiqueta actual, el número de tareas completadas y las no completadas.\n",
    "        if not_done > 0 and callback:\n",
    "            callback(tag, done, not_done)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834f7991-17cf-4421-835c-50ad47fd5b12",
   "metadata": {},
   "source": [
    "Esta función monitorea el progreso de un conjunto de futuros (tareas enviadas a ejecución en el Executor). Informa sobre la cantidad de tareas completadas y pendientes, permitiendo visualizar el estado de la ejecución en tiempo real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2037f6fe-fe2f-4fe1-b617-af6534940db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def async_map(executor, mapper, data):\n",
    "    # Se inicializa una lista vacía para almacenar los objetos Future.\n",
    "    futures = []\n",
    "\n",
    "    # Itera sobre cada elemento en el conjunto de datos de entrada.\n",
    "    for datum in data:\n",
    "        # Utiliza el executor para lanzar la función mapper de forma asincrónica.\n",
    "        # `executor.submit()` programa la función `mapper` para ser ejecutada con el argumento `datum`.\n",
    "        # Esto devuelve un objeto Future que representa la ejecución pendiente o futura.\n",
    "        futures.append(executor.submit(mapper, datum))\n",
    "\n",
    "    # Devuelve la lista de objetos Future. Cada Future contendrá el resultado de aplicar\n",
    "    # la función `mapper` a un elemento de `data` una vez que se complete la ejecución.\n",
    "    return futures\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6242c917-ab3c-4e1d-bbdc-999ecf8e59c7",
   "metadata": {},
   "source": [
    "Reemplaza directamente el uso de executor.map() con una lista de futuros, permitiendo un manejo más fino y personalizado de cada tarea individual, incluyendo la posibilidad de monitorización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10cbee5-ad85-469c-bbc1-3adb5310c68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_reduce_less_naive(my_input, mapper, reducer, callback=None):\n",
    "    # Crea un ThreadPoolExecutor con un máximo de dos trabajadores.\n",
    "    # El contexto 'with' asegura que el executor se cierra adecuadamente después de su uso.\n",
    "    with Executor(max_workers=2) as executor:\n",
    "        # Utiliza la función async_map para lanzar las tareas de mapeo de forma asincrónica.\n",
    "        # Retorna una lista de objetos Future que representan las operaciones de mapeo.\n",
    "        futures = async_map(executor, mapper, my_input)\n",
    "        \n",
    "        # Función para reportar el progreso de las tareas de mapeo.\n",
    "        # Utiliza un callback para informar sobre el estado de la ejecución de mapeo.\n",
    "        report_progress(futures, 'map', callback)\n",
    "        \n",
    "        # Recolecta los resultados de las tareas de mapeo completadas.\n",
    "        # `f.result()` bloquea hasta que el futuro se complete y devuelve el resultado.\n",
    "        map_results = map(lambda f: f.result(), futures)\n",
    "\n",
    "        # Utiliza defaultdict para agrupar los valores por claves generadas en el mapeo.\n",
    "        distributor = defaultdict(list)\n",
    "        for key, value in map_results:\n",
    "            # Agrega el valor al listado correspondiente a la clave en el diccionario.\n",
    "            distributor[key].append(value)\n",
    "\n",
    "        # Lanza las tareas de reducción de forma asincrónica sobre los grupos de valores.\n",
    "        # Cada tarea de reducción procesa los valores asociados a una clave.\n",
    "        futures = async_map(executor, reducer, distributor.items())\n",
    "        \n",
    "        # Función para reportar el progreso de las tareas de reducción.\n",
    "        report_progress(futures, 'reduce', callback)\n",
    "        \n",
    "        # Recolecta los resultados finales de las tareas de reducción.\n",
    "        results = map(lambda f: f.result(), futures)\n",
    "\n",
    "    # Devuelve los resultados de la operación de MapReduce.\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214d5f8c-78b6-413b-832d-1b248d96214c",
   "metadata": {},
   "source": [
    "Implementa el proceso MapReduce usando las funciones async_map y report_progress. La función ahora es capaz de reportar el progreso tanto de la fase de mapeo como de reducción."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef83708f-9424-4739-98de-38c504ff62e4",
   "metadata": {},
   "source": [
    "#### Mejoras con respecto al código anterior\n",
    "\n",
    "- Monitoreo de progreso: La inclusión de report_progress permite un seguimiento en tiempo real de la ejecución, lo cual es útil en entornos de producción para diagnóstico y monitoreo.\n",
    "- Manejo explícito de concurrencia: Usar async_map con executor.submit() en lugar de executor.map() da un control más detallado sobre cada tarea y permite manejar excepciones, cancelaciones y otras operaciones a nivel de tarea individual.\n",
    "- Configuración de parámetros del Executor: Permite ajustar el número de trabajadores (max_workers), lo que puede optimizar el rendimiento según las características del hardware y la carga de trabajo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af72e40-15dd-483f-82d1-9bf2c447b2b9",
   "metadata": {},
   "source": [
    "El programa ejecuta la función map_reduce_less_naive sobre una lista de palabras, utilizando las funciones emitter y counter como funciones de mapeo y reducción, respectivamente. Imprime los resultados, que muestran cada palabra y su frecuencia, de manera ordenada por frecuencia. Esto es idéntico en función al código anterior, pero con una ejecución más sofisticada y transparente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fcec41-166c-4fa3-82fa-78c45d3e0517",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from concurrent.futures import ThreadPoolExecutor as Executor, as_completed\n",
    "import os\n",
    "\n",
    "# Definimos las funciones de mapeo y reducción\n",
    "def map_function(word):\n",
    "    return (word, 1)\n",
    "\n",
    "def reduce_function(item):\n",
    "    word, counts = item\n",
    "    return (word, sum(counts))\n",
    "\n",
    "# Función para realizar MapReduce con seguimiento del progreso\n",
    "def map_reduce_with_progress(my_input, mapper, reducer):\n",
    "    # Distribuye los resultados del mapeo\n",
    "    distributor = defaultdict(list)\n",
    "\n",
    "    # Inicia un ejecutor de hilos\n",
    "    with Executor() as executor:\n",
    "        # Primero, ejecutamos el mapeo\n",
    "        future_to_word = {executor.submit(mapper, word): word for word in my_input}\n",
    "        for future in as_completed(future_to_word):\n",
    "            word, count = future.result()\n",
    "            distributor[word].append(count)\n",
    "\n",
    "        # Después, ejecutamos la reducción\n",
    "        results = executor.map(reducer, distributor.items())\n",
    "    \n",
    "    # Convertimos los resultados a una lista y retornamos\n",
    "    return list(results)\n",
    "\n",
    "# Preparamos los datos de entrada leyendo desde un archivo\n",
    "def prepare_data(file_path):\n",
    "    with open(file_path, 'rt', encoding='utf-8') as file:\n",
    "        # Limpiamos y dividimos las palabras, filtramos las cadenas vacías\n",
    "        words = filter(None, [word.strip().rstrip() for line in file for word in line.split()])\n",
    "    return words\n",
    "\n",
    "# Ejecutamos el proceso de MapReduce\n",
    "if __name__ == \"__main__\":\n",
    "    words = prepare_data('texto.txt')\n",
    "    results = map_reduce_with_progress(words, map_function, reduce_function)\n",
    "\n",
    "    # Ordenamos los resultados y los imprimimos\n",
    "    for word, count in sorted(results, key=lambda x: x[1], reverse=True):\n",
    "        print(f\"Palabra: '{word}', Frecuencia: {count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe54f67-0331-4c8c-85da-09a33a4519a6",
   "metadata": {},
   "source": [
    "El código anterior es otra variante de una implementación del patrón MapReduce utilizando programación concurrente, específicamente a través de ThreadPoolExecutor del módulo concurrent.futures.\n",
    "\n",
    "**Similitudes:**\n",
    "\n",
    "- Uso de Concurrency: Al igual que en los códigos anteriores, este código utiliza ThreadPoolExecutor para paralelizar las tareas de mapeo y reducción, lo que permite una ejecución más eficiente al procesar múltiples elementos en paralelo.\n",
    "\n",
    "Estructura de MapReduce:\n",
    "\n",
    "- Mapeo: Al igual que en otros ejemplos, hay una función de mapeo (map_function) que procesa cada palabra de entrada y la mapea a un par (palabra, 1).\n",
    "- Reducción: Utiliza una función de reducción (reduce_function) que suma las cuentas de cada palabra, similar a cómo se hace en ejemplos anteriores.\n",
    "\n",
    "Uso de defaultdict: Utiliza defaultdict para colectar y agrupar resultados del mapeo antes de la reducción, de la misma manera que en los códigos anteriores.\n",
    "\n",
    "**Diferencias:**\n",
    "\n",
    "Manejo de Future:\n",
    "\n",
    "- En este código, se utiliza future_to_word para mapear cada futuro a la palabra que fue procesada, lo que facilita la gestión y seguimiento de las tareas a medida que se completan. Esto permite un control más granular sobre las operaciones concurrentes.\n",
    "\n",
    " Utiliza as_completed para iterar sobre los futuros a medida que se completan, lo cual es una técnica eficiente para manejar tareas que pueden terminar en tiempos diferentes.\n",
    "\n",
    "Feedback de progreso:\n",
    "\n",
    "- A diferencia de los códigos anteriores que implementaban funciones específicas para reportar el progreso (report_progress), este código no incluye una función explícita para reportar progreso. Sin embargo, el uso de as_completed permite actuar tan pronto como una tarea se completa, lo que puede ser útil para actualizar interfaces de usuario o logs en tiempo real.\n",
    "\n",
    "Lectura y preparación de datos:\n",
    "\n",
    "- Este código incluye una función prepare_data que lee directamente desde un archivo y prepara los datos para el proceso de MapReduce. Esto contrasta con algunos de los ejemplos anteriores donde los datos eran simplemente una lista de palabras o eran preparados fuera de las funciones principales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383ea395-cd12-4b18-b44d-1ac6faffb629",
   "metadata": {},
   "source": [
    "#### Ejercicio 1: Implementación de MapReduce mejorada\n",
    "Modifica una de las implementaciones de MapReduce presentadas para incluir un manejo de excepciones robusto que permita la aplicación continuar incluso si una de las tareas de mapeo o reducción falla. Además, implementa un sistema de logging que registre eventos como el inicio y fin de cada tarea, errores, y el progreso general de las operaciones de mapeo y reducción.\n",
    "Sugerencia: Utiliza el módulo logging de Python para los registros y try-except dentro de las funciones de mapeo y reducción.\n",
    "\n",
    "#### Ejercicio 2: Paralelización de la lectura de datos\n",
    "Modifica la función prepare_data para que pueda leer de múltiples archivos en paralelo usando ThreadPoolExecutor, y luego combina los resultados en una sola lista de palabras antes de pasarlas al proceso de MapReduce.\n",
    "Sugerencia: Supón que tienes varios archivos de texto (texto1.txt, texto2.txt, etc.) y usa executor.map para leer cada uno en paralelo.\n",
    "\n",
    "\n",
    "#### Ejercicio 3: Reducción por claves específicas\n",
    "Añade una funcionalidad que permita especificar un conjunto de claves (palabras) de interés, y modifica el proceso de reducción para que solo sume las cuentas de estas claves seleccionadas.\n",
    "\n",
    "Sugerencia: Puedes modificar la función de reducción para que primero verifique si la clave está en el conjunto de claves de interés antes de procesarla.\n",
    "\n",
    "#### Ejercicio 4: Escalabilidad en el número de workers\n",
    "Realiza pruebas de rendimiento variando el número de workers en ThreadPoolExecutor para observar cómo afecta al tiempo total de procesamiento del MapReduce.\n",
    "\n",
    "Sugerencia: Utiliza un conjunto grande de datos y prueba con configuraciones de 1, 2, 4, 8 y 16 workers. Registra los tiempos de ejecución para cada configuración y analiza los resultados.\n",
    "\n",
    "#### Ejercicio 5: MapReduce con Asyncio\n",
    "Transforma el código MapReduce para que utilice programación asincrónica. Esto incluirá convertir las funciones de mapeo y reducción en funciones asincrónicas y usar asyncio.gather para manejar la concurrencia.\n",
    "\n",
    "Sugerencia: Familiarízate con asyncio y cómo las coroutines pueden ser utilizadas para tareas I/O-bound como la lectura de archivos.\n",
    "\n",
    "\n",
    "#### Ejercicio 6: Implementación Multihilo de MapReduce\n",
    "Aprovecha ThreadPoolExecutor para implementar una versión de MapReduce que procese en paralelo tanto la fase de mapeo como la de reducción. Añade manejo de errores y asegúrate de que el sistema pueda recuperarse de fallos en las tareas individuales.\n",
    "\n",
    "Sugerencia: Incorpora logging para monitorear el progreso y los posibles errores en las distintas etapas del procesamiento.\n",
    "\n",
    "#### Ejercicio 7: MapReduce distribuido sobre red\n",
    "Desarrolla un sistema básico donde un servidor central coordina múltiples clientes que realizan tareas de mapeo y reducción. Los clientes pueden estar en diferentes máquinas y comunicarse con el servidor para obtener tareas y devolver resultados.\n",
    "\n",
    "Sugerencia: Utiliza sockets para la comunicación entre el servidor y los clientes. Implementa funcionalidades básicas en el servidor para asignar tareas y recolectar resultados.\n",
    "\n",
    "#### Ejercicio 8: Análisis de rendimiento con diferentes niveles de concurrencia\n",
    "Realiza un experimento controlado donde ejecutas la misma carga de trabajo de MapReduce con diferentes números de hilos o procesos. Documenta cómo cambia el rendimiento con respecto a diferentes configuraciones.\n",
    "\n",
    "Sugerencia: Puedes usar ThreadPoolExecutor y ProcessPoolExecutor para variar entre multihilo y multiproceso, respectivamente. Considera la utilización de CPU y la eficiencia de I/O en tu análisis.\n",
    "\n",
    "#### Ejercicio 9: MapReduce asincrónico\n",
    "Reescribe una de las implementaciones de MapReduce para usar asyncio y coroutines en lugar de hilos, lo que puede ser más eficiente para operaciones I/O-bound como la lectura de archivos grandes o la espera de respuestas de red.\n",
    "\n",
    "Sugerencia: Asegúrate de comprender cómo asyncio gestiona la concurrencia de I/O y cómo puede integrarse con operaciones de CPU-bound mediante el uso de loop.run_in_executor.\n",
    "\n",
    "#### Ejercicio 10: Tolerancia a fallos en sistemas de MapReduce\n",
    "Añade características de tolerancia a fallos al sistema MapReduce para manejar errores como la caída de un nodo de procesamiento. Implementa estrategias para reasignar tareas de nodos fallidos a nodos en funcionamiento sin perder datos.\n",
    "\n",
    "Sugerencia: Considera el uso de checkpoints o la replicación de tareas para garantizar que el sistema pueda recuperarse de fallos sin necesidad de reiniciar todo el proceso desde el principio.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59786186",
   "metadata": {},
   "source": [
    "#### Ejercicio 1: Implementación de MapReduce mejorada\n",
    "Modifica una de las implementaciones de MapReduce presentadas para incluir un manejo de excepciones robusto que permita la aplicación continuar incluso si una de las tareas de mapeo o reducción falla. Además, implementa un sistema de logging que registre eventos como el inicio y fin de cada tarea, errores, y el progreso general de las operaciones de mapeo y reducción.\n",
    "Sugerencia: Utiliza el módulo logging de Python para los registros y try-except dentro de las funciones de mapeo y reducción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c31d4e81-00c3-4d4e-917a-eee17fb4d875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabra: 'Hola', Frecuencia: 2\n",
      "Palabra: 'Python', Frecuencia: 2\n",
      "Palabra: 'como', Frecuencia: 1\n",
      "Palabra: 'esta', Frecuencia: 1\n",
      "Palabra: 'es', Frecuencia: 1\n"
     ]
    }
   ],
   "source": [
    "## Tus respuestas\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "from concurrent.futures import ThreadPoolExecutor as Executor, as_completed\n",
    "import os\n",
    "\n",
    "logging.basicConfig(filename='map_reduce_log.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Definimos las funciones de mapeo y reducción\n",
    "def map_function(word):\n",
    "    try:\n",
    "        result=(word, 1)\n",
    "        logging.info(f\"Mapeo de '{word}' exitoso\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error en el mapeo de '{word}': {e}\")\n",
    "        raise\n",
    "\n",
    "def reduce_function(item):\n",
    "    try:\n",
    "        word, counts = item\n",
    "        result = (word, sum(counts))\n",
    "        logging.info(f\"Reducción de '{word}' exitosa\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error en la reducción de '{word}': {e}\")\n",
    "        raise\n",
    "\n",
    "# Función para realizar MapReduce con seguimiento del progreso\n",
    "def map_reduce_with_progress(my_input, mapper, reducer):\n",
    "    # Distribuye los resultados del mapeo\n",
    "    distributor = defaultdict(list)\n",
    "\n",
    "    # Inicia un ejecutor de hilos\n",
    "    with Executor() as executor:\n",
    "        # Primero, ejecutamos el mapeo\n",
    "        future_to_word = {executor.submit(mapper, word): word for word in my_input}\n",
    "        for future in as_completed(future_to_word):\n",
    "            word, count = future.result()\n",
    "            distributor[word].append(count)\n",
    "\n",
    "        # Después, ejecutamos la reducción\n",
    "        results = executor.map(reducer, distributor.items())\n",
    "    \n",
    "    # Convertimos los resultados a una lista y retornamos\n",
    "    return list(results)\n",
    "\n",
    "# Preparamos los datos de entrada leyendo desde un archivo\n",
    "def prepare_data(file_path):\n",
    "    with open(file_path, 'rt', encoding='utf-8') as file:\n",
    "        # Limpiamos y dividimos las palabras, filtramos las cadenas vacías\n",
    "        words = filter(None, [word.strip().rstrip() for line in file for word in line.split()])\n",
    "    return words\n",
    "\n",
    "# Ejecutamos el proceso de MapReduce\n",
    "if __name__ == \"__main__\":\n",
    "    words = 'Hola Python Hola como esta es Python'.split()\n",
    "    results = map_reduce_with_progress(words, map_function, reduce_function)\n",
    "\n",
    "    # Ordenamos los resultados y los imprimimos\n",
    "    for word, count in sorted(results, key=lambda x: x[1], reverse=True):\n",
    "        print(f\"Palabra: '{word}', Frecuencia: {count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78490cb9-43ce-4a9b-9dba-ef2dfde9639a",
   "metadata": {},
   "source": [
    "### Parte 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81c1be0-1bb8-4caf-a669-60fe387133db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from concurrent.futures import ProcessPoolExecutor as Executor\n",
    "from time import sleep\n",
    "# Codigo de Tiago Rodriguez\n",
    "\n",
    "def report_progress(futures, tag, callback):\n",
    "    # Inicializa los contadores de tareas completadas y no completadas.\n",
    "    not_done = 1\n",
    "    done = 0\n",
    "    # Bucle mientras haya tareas no completadas.\n",
    "    while not_done > 0:\n",
    "        not_done = 0\n",
    "        done = 0\n",
    "        # Itera sobre cada futuro para verificar si está completado.\n",
    "        for fut in futures:\n",
    "            if fut.done():\n",
    "                done += 1  # Incrementa el contador de completadas.\n",
    "            else:\n",
    "                not_done += 1  # Incrementa el contador de no completadas.\n",
    "        # Pausa el bucle por medio segundo para reducir la carga de comprobación.\n",
    "        sleep(0.5)\n",
    "        # Si hay una función de callback, informa el progreso actual.\n",
    "        if callback:\n",
    "            callback(tag, done, not_done)\n",
    "    \n",
    "\n",
    "def async_map(executor, mapper, data):\n",
    "    # Lista para almacenar los futuros.\n",
    "    futures = []\n",
    "    # Envía cada elemento de los datos a la función mapper usando el executor.\n",
    "    for datum in data:\n",
    "        futures.append(executor.submit(mapper, datum))\n",
    "    # Devuelve la lista de futuros.\n",
    "    return futures\n",
    "\n",
    "\n",
    "def map_less_naive(executor, my_input, mapper):\n",
    "    # Aplica la función de mapeo a cada entrada y devuelve los resultados.\n",
    "    map_results = async_map(executor, mapper, my_input)\n",
    "    return map_results\n",
    "\n",
    "\n",
    "def map_reduce_less_naive(my_input, mapper, reducer, callback=None):\n",
    "    # Crea un ejecutor con un máximo de dos trabajadores.\n",
    "    with Executor(max_workers=2) as executor:\n",
    "        # Mapea las entradas y monitorea el progreso.\n",
    "        futures = async_map(executor, mapper, my_input)\n",
    "        report_progress(futures, 'map', callback)\n",
    "        # Obtiene los resultados del mapeo.\n",
    "        map_results = map(lambda f: f.result(), futures)\n",
    "        # Agrupa los resultados por clave.\n",
    "        distributor = defaultdict(list)\n",
    "        for key, value in map_results:\n",
    "            distributor[key].append(value)\n",
    "\n",
    "        # Realiza el proceso de reducción y monitorea el progreso.\n",
    "        futures = async_map(executor, reducer, distributor.items())\n",
    "        report_progress(futures, 'reduce', callback)\n",
    "        # Obtiene los resultados de la reducción.\n",
    "        results = map(lambda f: f.result(), futures)\n",
    "    # Devuelve los resultados finales.\n",
    "    return results\n",
    "\n",
    "\n",
    "def emitter(word):\n",
    "    # Función de mapeo que emite cada palabra con un conteo inicial de 1.\n",
    "    return word, 1\n",
    "\n",
    "\n",
    "def counter(emitted):\n",
    "    # Función de reducción que suma los conteos de cada palabra.\n",
    "    return emitted[0], sum(emitted[1])\n",
    "\n",
    "\n",
    "def reporter(tag, done, not_done):\n",
    "    # Imprime el estado del progreso para la operación actual.\n",
    "    print(f'Operacion {tag}: {done}/{done+not_done}')\n",
    "\n",
    "# Prepara los datos y ejecuta el proceso MapReduce.\n",
    "words = 'Python es super Python rocks'.split(' ')\n",
    "a = map_reduce_less_naive(words, emitter, counter, reporter)\n",
    "\n",
    "# Imprime los resultados ordenados por frecuencia.\n",
    "for i in sorted(a, key=lambda x: x[1]):\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56920770-28aa-486c-a825-1b2674c3b597",
   "metadata": {},
   "source": [
    "Este código es una variante del patrón de diseño MapReduce, implementado utilizando programación concurrente con ProcessPoolExecutor de la biblioteca concurrent.futures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5df6f82-3705-46bc-9626-b53b34acf165",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from concurrent.futures import ProcessPoolExecutor as Executor\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b3a101-8ce8-4cae-a382-5ee4ce22de3d",
   "metadata": {},
   "source": [
    "- defaultdict: Utilizado para agrupar automáticamente valores en listas sin necesidad de inicializar manualmente cada clave.\n",
    "- ProcessPoolExecutor: Una variante de Executor que utiliza procesos en lugar de hilos. Esto puede ser ventajoso para tareas computacionalmente intensivas porque evita problemas de Global Interpreter Lock (GIL) en Python.\n",
    "- sleep: Utilizado para pausar la ejecución entre verificaciones del estado de las tareas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7937092-69b1-4340-8bd5-8a8fafdc2d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_less_naive(executor, my_input, mapper):\n",
    "    # Aplica la función de mapeo a cada entrada y devuelve los resultados.\n",
    "    map_results = async_map(executor, mapper, my_input)\n",
    "    return map_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02590cd6-666b-4de7-b6e0-5c85da130797",
   "metadata": {},
   "source": [
    "Esta función se centra exclusivamente en la etapa de mapeo del proceso MapReduce:\n",
    "\n",
    "- Aplicación de la función de mapeo: Recibe un ejecutor, datos de entrada (my_input) y una función mapper. Utiliza async_map para enviar cada elemento de entrada al ejecutor, donde la función mapper se aplica de manera concurrente.\n",
    "- Devolución de resultados de mapeo: A diferencia de map_reduce_less_naive, esta función solo devuelve los resultados de la fase de mapeo, sin proceder a la reducción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0ac66f-d410-41b0-bd4d-6c8ca729ee59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_reduce_less_naive(my_input, mapper, reducer, callback=None):\n",
    "    # Crea un ejecutor con un máximo de dos trabajadores.\n",
    "    with Executor(max_workers=2) as executor:\n",
    "        # Mapea las entradas y monitorea el progreso.\n",
    "        futures = async_map(executor, mapper, my_input)\n",
    "        report_progress(futures, 'map', callback)\n",
    "        # Obtiene los resultados del mapeo.\n",
    "        map_results = map(lambda f: f.result(), futures)\n",
    "        # Agrupa los resultados por clave.\n",
    "        distributor = defaultdict(list)\n",
    "        for key, value in map_results:\n",
    "            distributor[key].append(value)\n",
    "\n",
    "        # Realiza el proceso de reducción y monitorea el progreso.\n",
    "        futures = async_map(executor, reducer, distributor.items())\n",
    "        report_progress(futures, 'reduce', callback)\n",
    "        # Obtiene los resultados de la reducción.\n",
    "        results = map(lambda f: f.result(), futures)\n",
    "    # Devuelve los resultados finales.\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329aedce-ab07-469d-8e11-e0809f2922f1",
   "metadata": {},
   "source": [
    "Esta función ejecuta un proceso completo de MapReduce y se encarga de:\n",
    "\n",
    "- Inicia un ejecutor con procesos: Utiliza ProcessPoolExecutor con un máximo de dos trabajadores. Esto permite que las tareas se ejecuten en procesos separados, lo cual es útil para evitar el bloqueo del Global Interpreter Lock (GIL) en Python, y es especialmente beneficioso para tareas computacionalmente intensivas.\n",
    "- Mapeo de entradas: Utiliza la función async_map para enviar tareas de mapeo al ejecutor. Cada tarea de mapeo aplica la función mapper a un elemento de my_input. async_map devuelve una lista de objetos Future, cada uno representando una tarea de mapeo pendiente o en ejecución.\n",
    "- Monitoreo del progreso de mapeo: report_progress se llama con los futures del mapeo para informar el progreso de estas tareas hasta que todas estén completadas. Esto se hace mediante una función de callback que puede actualizar interfaces de usuario o logs.\n",
    "- Recolección y agrupación de resultados de mapeo: Una vez que todos los futuros de mapeo están completos, se recogen los resultados y se agrupan por clave usando defaultdict(list). Esto prepara los datos para la etapa de reducción.\n",
    "- Reducción de resultados: Similar a la etapa de mapeo, se envían tareas de reducción al mismo ejecutor utilizando async_map, pero esta vez aplicando la función reducer a cada grupo de valores asociados a las mismas claves.\n",
    "- Monitoreo del progreso de reducción: Al igual que con el mapeo, se monitorea el progreso de las tareas de reducción.\n",
    "- Recolección de resultados finales: Finalmente, se recogen los resultados de las tareas de reducción y se devuelven."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce82e33-9abb-4bd1-922e-5c1bb082fe83",
   "metadata": {},
   "source": [
    "**Relación entre map_reduce_less_naive y map_less_naive**\n",
    "- map_less_naive puede considerarse como un subcomponente dentro de map_reduce_less_naive, específicamente encargado de la ejecución del mapeo.\n",
    "- map_reduce_less_naive es una implementación más completa que no solo maneja el mapeo utilizando map_less_naive (o su funcionalidad equivalente), sino que también integra la reducción y el seguimiento del progreso en un solo flujo de trabajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070b627b-1613-43a4-8ef5-9d20c8b8829f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import multiprocessing as mp\n",
    "from time import sleep\n",
    "\n",
    "def report_progress(futures, tag, callback):\n",
    "    # Inicializa contadores para tareas completadas y no completadas.\n",
    "    not_done = 1\n",
    "    done = 0\n",
    "    # Continúa mientras haya tareas no completadas.\n",
    "    while not_done > 0:\n",
    "        not_done = 0\n",
    "        done = 0\n",
    "        # Itera sobre los objetos AsyncResult para verificar su estado.\n",
    "        for fut in futures:\n",
    "            if fut.ready():\n",
    "                done += 1  # Incrementa contador de completados si el futuro ha terminado.\n",
    "            else:\n",
    "                not_done += 1  # Incrementa contador de no completados si el futuro aún está en progreso.\n",
    "        sleep(0.5)  # Pausa para no saturar la CPU.\n",
    "        # Si se proporciona una función de callback, llama a la función con el estado actual.\n",
    "        if callback:\n",
    "            callback(tag, done, not_done)\n",
    "\n",
    "def map_reduce(my_input, mapper, reducer, callback=None):\n",
    "    # Utiliza un pool de procesos para ejecutar tareas de mapeo y reducción.\n",
    "    with mp.Pool(2) as pool:\n",
    "        # Aplica la función mapper a cada elemento del input de manera asincrónica.\n",
    "        futures = [pool.apply_async(mapper, (word,)) for word in my_input]\n",
    "        report_progress(futures, 'map', callback)\n",
    "        # Recolecta los resultados del mapeo.\n",
    "        map_results = [future.get() for future in futures]\n",
    "\n",
    "        # Agrupa los resultados de mapeo usando un defaultdict.\n",
    "        distributor = defaultdict(list)\n",
    "        for key, value in map_results:\n",
    "            distributor[key].append(value)\n",
    "\n",
    "        # Aplica la función reducer a cada grupo de elementos de manera asincrónica.\n",
    "        reduce_futures = [pool.apply_async(reducer, (item,)) for item in distributor.items()]\n",
    "        report_progress(reduce_futures, 'reduce', callback)\n",
    "        # Recolecta los resultados de la reducción.\n",
    "        results = [future.get() for future in reduce_futures]\n",
    "    return results\n",
    "\n",
    "def emitter(word):\n",
    "    sleep(1)\n",
    "    return word, 1\n",
    "\n",
    "def counter(emitted):\n",
    "    return emitted[0], sum(emitted[1])\n",
    "\n",
    "def reporter(tag, done, not_done):\n",
    "    print(f'Operacion {tag}: {done}/{not_done}')\n",
    "\n",
    "words = 'Python es super, Python rocks'.split(' ')\n",
    "a = map_reduce(words, emitter, counter, reporter)\n",
    "\n",
    "for i in sorted(a, key=lambda x: x[1]):\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c4ccee-5aeb-4ee7-9041-46c05f5e0a29",
   "metadata": {},
   "source": [
    "El código anterior es una implementación de un proceso de MapReduce utilizando el módulo multiprocessing en Python, que maneja la concurrencia mediante procesos en lugar de hilos. Además, incorpora funciones para monitorizar el progreso de las tareas de mapeo y reducción. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191a6961-e03e-4635-9214-cba49922f59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_reduce(my_input, mapper, reducer, callback=None):\n",
    "    # Implementa el proceso completo de MapReduce utilizando un pool de procesos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc24d391-11e5-4dba-aa90-1f9b15e9c64a",
   "metadata": {},
   "source": [
    "- Inicialización de un pool de procesos: Se crea un Pool de dos procesos para manejar las tareas en paralelo.\n",
    "- Mapeo asincrónico: Se envían tareas de mapeo de forma asincrónica para cada elemento del input.\n",
    "- Agrupación de resultados: Los resultados del mapeo se agrupan por claves en un defaultdict.\n",
    "- Reducción asincrónica: Se procesan las reducciones de forma asincrónica para cada grupo de valores asociados a una clave.\n",
    "- Recolección de resultados finales: Los resultados finales de la reducción se recogen y devuelven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c426dc-e90e-45d5-814e-69c163a62c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emitter(word):\n",
    "    # Simula una operación de mapeo que tarda tiempo, ideal para procesos intensivos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ca8fa4-4571-4561-9ca2-f89f629aaa21",
   "metadata": {},
   "source": [
    "Función de mapeo (emitter): Toma una palabra, espera un segundo (simulando carga de procesamiento) y devuelve un par (palabra, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c2b783-7918-4ffe-876e-050776853dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def counter(emitted):\n",
    "    # Reduce los resultados sumando los conteos para cada palabra clave."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7192307d-64c3-481d-917e-5662114c37fd",
   "metadata": {},
   "source": [
    "Función de reducción (counter): Toma una tupla de palabra y lista de conteos, y devuelve la suma de esos conteos junto con la palabra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd35f23-a993-4208-92d4-27d2df8b73f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reporter(tag, done, not_done):\n",
    "    # Imprime el estado del progreso para las operaciones de mapeo o reducción.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4273c2-40d5-4baa-9d63-f67d75b78d6f",
   "metadata": {},
   "source": [
    "reporter: Es llamada por report_progress para imprimir el estado actual del progreso, mostrando cuántas tareas han sido completadas y cuántas están pendientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba949b34-ac8c-4a9c-b721-97dfd7146a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = 'Python es super, Python rocks'.split(' ')\n",
    "a = map_reduce(words, emitter, counter, reporter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d035d7d-dede-4dde-8cfb-b040207a9f4d",
   "metadata": {},
   "source": [
    "Proceso de MapReduce: El conjunto de palabras es procesado usando las funciones de mapeo y reducción definidas, con la capacidad de monitorizar el progreso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf5280c-8499-42a0-b59b-29e2e7b5af75",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sorted(a, key=lambda x: x[1]):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd192819-b842-489c-8e4d-f14993c5a803",
   "metadata": {},
   "source": [
    "Los resultados finales del proceso de MapReduce son ordenados por la frecuencia de las palabras y luego impresos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3634ef8a-8223-4cf3-8c1c-73d8546c78a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import multiprocessing as mp\n",
    "from time import sleep\n",
    "#Tiago Rodriguez\n",
    "\n",
    "def report_progress(map_returns, tag, callback):\n",
    "    done = 0\n",
    "    num_jobs = len(map_returns)\n",
    "    while num_jobs > done:\n",
    "        done = 0\n",
    "        for ret in map_returns:\n",
    "            if ret.ready():\n",
    "                done += 1\n",
    "        sleep(0.5)\n",
    "        if callback:\n",
    "            callback(tag, done, num_jobs - done)\n",
    "\n",
    "\n",
    "def async_map(pool, mapper, data):\n",
    "    async_returns = []\n",
    "    for datum in data:\n",
    "        async_returns.append(pool.apply_async(\n",
    "            mapper, (datum, )))  #The tuple\n",
    "    return async_returns\n",
    "\n",
    "\n",
    "def map_reduce(pool, my_input, mapper, reducer, callback=None):\n",
    "    map_returns = async_map(pool, mapper, my_input)\n",
    "    report_progress(map_returns, 'map', callback)\n",
    "    map_results = [ret.get() for ret in map_returns]\n",
    "    distributor = defaultdict(list)\n",
    "    for key, value in map_results:\n",
    "        distributor[key].append(value)\n",
    "    returns = async_map(pool, reducer, distributor.items())\n",
    "    results = [ret.get() for ret in returns]\n",
    "    return results\n",
    "\n",
    "\n",
    "def emitter(word):\n",
    "    sleep(1)\n",
    "    return word, 1\n",
    "\n",
    "\n",
    "def counter(emitted):\n",
    "    return emitted[0], sum(emitted[1])\n",
    "\n",
    "\n",
    "def reporter(tag, done, not_done):\n",
    "    print(f'Operacion {tag}: {done}/{done+not_done}')\n",
    "\n",
    "\n",
    "words = 'Python es super Python rocks'.split(' ')\n",
    "pool = mp.Pool(2)\n",
    "results = map_reduce(pool, words, emitter, counter, reporter)\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "\n",
    "for result in sorted(results, key=lambda x: x[1]):\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf25407d-9deb-428c-862a-8813339c317d",
   "metadata": {},
   "source": [
    "\n",
    "El código proporcionado mejora algunos aspectos clave respecto al código anterior relacionados con la eficiencia y la estructura del manejo de procesos y tareas asincrónicas. A continuación, se destacan las mejoras y cambios realizados:\n",
    "\n",
    "1 . Manejo mejorado de procesos del Pool\n",
    "\n",
    "En el código anterior, el manejo del Pool de multiprocessing se realizaba dentro de la función map_reduce, lo cual limitaba su reutilización para múltiples tareas sin recrear el pool cada vez. En el nuevo código, el pool se crea fuera de la función map_reduce y se pasa como argumento. Esto permite mayor flexibilidad y eficiencia, ya que el pool puede ser utilizado para múltiples tareas o múltiples llamadas a map_reduce sin necesidad de inicialización y terminación repetidas. El cierre (close()) y la espera de que todas las tareas se completen (join()) se manejan también fuera de la función map_reduce, lo que es una práctica recomendada para un manejo limpio y eficiente de los recursos del pool.\n",
    "\n",
    "2 . Función async_map generalizada\n",
    "\n",
    "La función async_map se ha generalizado y extraído fuera de la función map_reduce, haciéndola una función independiente que puede ser reutilizada para aplicar cualquier función a un conjunto de datos de manera asincrónica utilizando un pool dado. Esto no solo mejora la modularidad del código sino que también aumenta la reusabilidad de la función async_map.\n",
    "\n",
    "3 . Reporte de progreso simplificado\n",
    "\n",
    "La función report_progress ha sido simplificada y ahora utiliza directamente el número total de tareas (num_jobs) y las tareas completadas (done) para reportar el progreso, haciendo su implementación más clara y directa. Esto mejora la legibilidad y facilita el mantenimiento del código.\n",
    "\n",
    "4 . Estructura de código más clara\n",
    "La estructura general del código ha mejorado en términos de claridad y separación de responsabilidades. Cada función tiene un propósito bien definido, y el flujo principal del programa es más claro. Esto facilita la lectura y comprensión del código, lo cual es crucial para la mantenibilidad a largo plazo y la colaboración en proyectos de software.\n",
    "\n",
    "5 . Manejo explícito de recursos\n",
    "El manejo explícito del Pool fuera de la función map_reduce (creación, cierre, y join) asegura que los recursos se liberan adecuadamente, lo que es especialmente importante en aplicaciones que pueden correr por largos periodos de tiempo o que manejan muchos datos. Esto previene potenciales fugas de recursos, que podrían llevar a problemas de rendimiento o estabilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61f29c2-2613-4424-ad71-b5e708825fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict  # Importa la clase defaultdict para crear diccionarios con valores predeterminados\n",
    "import multiprocessing as mp  # Importa el módulo multiprocessing para la programación concurrente\n",
    "import sys  # Importa el módulo sys para manipular la configuración del sistema\n",
    "import time  # Importa el módulo time para medir el tiempo de ejecución\n",
    "from time import sleep  # Importa la función sleep del módulo time para pausar la ejecución\n",
    "\n",
    "def report_progress(map_returns, tag, callback):\n",
    "    done = 0  # Inicializa el contador de tareas completadas\n",
    "    num_jobs = len(map_returns)  # Obtiene el número total de tareas\n",
    "    while num_jobs > done:  # Mientras haya tareas pendientes\n",
    "        done = 0  # Reinicia el contador de tareas completadas\n",
    "        for ret in map_returns:  # Itera sobre los resultados del mapeo\n",
    "            if ret.ready():  # Si la tarea ha finalizado\n",
    "                done += 1  # Incrementa el contador de tareas completadas\n",
    "        sleep(0.5)  # Espera un corto periodo de tiempo antes de volver a verificar\n",
    "        if callback:  # Si se proporciona una función de callback\n",
    "            callback(tag, done, num_jobs - done)  # Llama a la función de callback con el progreso actual\n",
    "\n",
    "def chunk0(my_list, chunk_size):\n",
    "    for i in range(0, len(my_list), chunk_size):  # Itera sobre la lista en incrementos del tamaño del fragmento\n",
    "        yield my_list[i:i + chunk_size]  # Produce fragmentos de la lista de tamaño especificado\n",
    "\n",
    "def chunk(my_iter, chunk_size):\n",
    "    chunk_list = []  # Inicializa una lista para contener los elementos del fragmento\n",
    "    for elem in my_iter:  # Itera sobre los elementos del iterable\n",
    "        chunk_list.append(elem)  # Agrega el elemento al fragmento\n",
    "        if len(chunk_list) == chunk_size:  # Si el fragmento alcanza el tamaño especificado\n",
    "            yield chunk_list  # Produce el fragmento\n",
    "            chunk_list = []  # Reinicia el fragmento\n",
    "    if len(chunk_list) > 0:  # Si quedan elementos en el fragmento\n",
    "        yield chunk_list  # Produce el fragmento\n",
    "\n",
    "def chunk_runner(fun, data):\n",
    "    ret = []  # Inicializa una lista para almacenar los resultados\n",
    "    for datum in data:  # Itera sobre los datos del fragmento\n",
    "        ret.append(fun(datum))  # Ejecuta la función en cada dato y agrega el resultado a la lista\n",
    "    return ret  # Devuelve la lista de resultados\n",
    "\n",
    "def chunked_async_map(pool, mapper, data, chunk_size):\n",
    "    async_returns = []  # Inicializa una lista para almacenar los resultados asincrónicos\n",
    "    for data_part in chunk(data, chunk_size):  # Itera sobre los fragmentos de datos\n",
    "        async_returns.append(pool.apply_async(chunk_runner, (mapper, data_part)))  # Aplica la función de manera asincrónica a cada fragmento\n",
    "    return async_returns  # Devuelve los resultados asincrónicos\n",
    "\n",
    "def map_reduce(pool, my_input, mapper, reducer, chunk_size, callback=None):\n",
    "    map_returns = chunked_async_map(pool, mapper, my_input, chunk_size)  # Realiza el mapeo en paralelo\n",
    "    report_progress(map_returns, 'map', callback)  # Informa sobre el progreso del mapeo\n",
    "    map_results = []  # Inicializa una lista para almacenar los resultados del mapeo\n",
    "    for ret in map_returns:  # Itera sobre los resultados del mapeo\n",
    "        map_results.extend(ret.get())  # Obtiene los resultados y los agrega a la lista\n",
    "    distributor = defaultdict(list)  # Crea un diccionario con valores predeterminados como listas\n",
    "    for key, value in map_results:  # Itera sobre los resultados del mapeo\n",
    "        distributor[key].append(value)  # Agrupa los valores por clave\n",
    "    returns = chunked_async_map(pool, reducer, distributor.items(), chunk_size)  # Realiza la reducción en paralelo\n",
    "    report_progress(returns, 'reduce', callback)  # Informa sobre el progreso de la reducción\n",
    "    results = []  # Inicializa una lista para almacenar los resultados finales\n",
    "    for ret in returns:  # Itera sobre los resultados de la reducción\n",
    "        results.extend(ret.get())  # Obtiene los resultados y los agrega a la lista\n",
    "    return results  # Devuelve los resultados finales\n",
    "\n",
    "def emitter(word):\n",
    "    return word, 1  # Emite cada palabra con un conteo inicial de 1\n",
    "\n",
    "def counter(emitted):\n",
    "    return emitted[0], sum(emitted[1])  # Suma los conteos de cada palabra\n",
    "\n",
    "def reporter(tag, done, not_done):\n",
    "    print(f'Operacion {tag}: {done}/{done+not_done}')  # Imprime el progreso de la operación\n",
    "\n",
    "def run_map_reduce(words, chunk_size):\n",
    "    pool = mp.Pool()  # Crea un grupo de procesos\n",
    "    start_time = time.time()  # Obtiene el tiempo de inicio\n",
    "    counts = map_reduce(pool, words, emitter, counter, chunk_size, reporter)  # Ejecuta el proceso MapReduce\n",
    "    pool.close()  # Cierra el grupo de procesos\n",
    "    pool.join()  # Espera a que todos los procesos terminen\n",
    "    end_time = time.time()  # Obtiene el tiempo de finalización\n",
    "    duration = end_time - start_time  # Calcula la duración del proceso\n",
    "    return duration  # Devuelve la duración\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    words = [word\n",
    "             for word in map(lambda x: x.strip().rstrip(),\n",
    "                             ' '.join(open('texto.txt', 'rt', encoding='utf-8').readlines()).split(' '))\n",
    "             if word != '' ]  # Lee las palabras de un archivo de texto y las almacena en una lista\n",
    "\n",
    "    chunk_sizes = [1, 10, 100, 1000, 10000]  # Tamaños de fragmentación a probar\n",
    "    results = []  # Inicializa una lista para almacenar los resultados\n",
    "\n",
    "    for size in chunk_sizes:  # Itera sobre los tamaños de fragmentación\n",
    "        duration = run_map_reduce(words, size)  # Ejecuta el proceso MapReduce con el tamaño de fragmentación actual\n",
    "        results.append((size, duration))  # Agrega el tamaño de fragmentación y la duración a la lista de resultados\n",
    "\n",
    "    print(\"Tam fragmentacion | Duracion\")  # Imprime la cabecera de la tabla de resultados\n",
    "    print(\"-\" * 20)  # Imprime una línea divisoria\n",
    "    for size, duration in results:  # Itera sobre los resultados\n",
    "        print(f\"{size:<10} | {duration:.2f} segundos\")  # Imprime el tamaño de fragmentación y la duración del proceso\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc6f9da-e101-48f6-915c-49deb80ba983",
   "metadata": {},
   "source": [
    "\n",
    "Este código introduce la optimización y paralelización avanzadas en un proceso de MapReduce utilizando el módulo multiprocessing. La principal mejora radica en el manejo de los datos en trozos o chunks, lo que puede aumentar significativamente la eficiencia al procesar grandes volúmenes de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8114ed02-c27b-4ec9-a631-a229c4f998f7",
   "metadata": {},
   "source": [
    "Algunas especificaciones de funciones:\n",
    "\n",
    "**chunk0(my_list, chunk_size)**:\n",
    "\n",
    "- Esta función toma una lista (my_list) y un tamaño de fragmento (chunk_size).\n",
    "- Divide la lista en segmentos de tamaño especificado utilizando un enfoque basado en iteración sobre índices.\n",
    "- Es una alternativa a la función chunk que se presenta posteriormente en el código. Ambas hacen básicamente lo mismo, pero con enfoques ligeramente diferentes.\n",
    "\n",
    "**chunk(my_iter, chunk_size)**:\n",
    "\n",
    "- Esta función toma un iterable (my_iter) y un tamaño de fragmento (chunk_size).\n",
    "- Itera sobre el iterable acumulando elementos en una lista hasta que alcanza el tamaño del fragmento especificado.\n",
    "- Cuando la lista alcanza el tamaño del fragmento, la función produce el fragmento y reinicia la lista.\n",
    "- Si al final del iterable quedan elementos que no forman un fragmento completo, también produce ese último fragmento.\n",
    "- Esta función es más genérica que chunk0 ya que puede funcionar con cualquier tipo de iterable, no solo listas.\n",
    "\n",
    "**chunk_runner(fun, data)**:\n",
    "\n",
    "- Esta función toma una función (fun) y una lista de datos (data).\n",
    "- Itera sobre los datos y aplica la función a cada elemento, acumulando los resultados en una lista.\n",
    "- Devuelve la lista de resultados.\n",
    "- Es una función de utilidad utilizada para ejecutar una función sobre un segmento de datos.\n",
    "\n",
    "**chunked_async_map(pool, mapper, data, chunk_size)**:\n",
    "\n",
    "- Esta función aplica un mapper de manera asincrónica a segmentos de datos.\n",
    "- Toma un pool de procesos (pool), una función de mapeo (mapper), los datos de entrada (data) y el tamaño del fragmento (chunk_size).\n",
    "- Divide los datos en fragmentos utilizando la función chunk.\n",
    "- Para cada fragmento de datos, utiliza el pool de procesos para aplicar asincrónicamente la función de mapeo a través de apply_async.\n",
    "- Devuelve una lista de objetos de resultado asincrónicos.\n",
    "\n",
    "Estas funciones son parte de la implementación del proceso de MapReduce. chunk y chunk0 dividen los datos en fragmentos, chunk_runner ejecuta el mapeo en cada fragmento, y chunked_async_map aplica el mapeo de manera asincrónica en paralelo sobre los fragmentos de datos. Estos fragmentos mapeados se agrupan y reducen posteriormente en la función map_reduce."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa42215-ce5a-48af-99ba-85a0c7865f89",
   "metadata": {},
   "source": [
    "El código proporcionado utiliza el módulo multiprocessing para implementar un proceso de MapReduce que maneja la entrada de datos en fragmentos o chunks, optimizando así el rendimiento al evitar el bloqueo del Global Interpreter Lock (GIL) en Python. Este enfoque permite una verdadera ejecución paralela en múltiples núcleos de CPU.\n",
    "\n",
    "El código ejecuta una función de MapReduce sobre una serie de palabras obtenidas de un archivo y mide el tiempo que tarda el proceso para diferentes tamaños de fragmentos. La salida del código será una serie de líneas que muestran el tiempo de ejecución para cada tamaño de fragmento probado. Por ejemplo, podrías ver algo como esto:\n",
    "\n",
    "```\n",
    "Tam fragmentacion | Duracion\n",
    "--------------------\n",
    "1          | 5.20 segundos\n",
    "10         | 2.30 segundos\n",
    "100        | 1.15 segundos\n",
    "1000       | 0.85 segundos\n",
    "10000      | 0.75 segundos\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fe945d-a189-4835-8e62-92b3a996c21e",
   "metadata": {},
   "source": [
    "#### Ejercicio 1: Modificar el número de procesos\n",
    "Modifica el código para cambiar dinámicamente el número de procesos en el pool (mp.Pool()). Realiza pruebas con diferentes configuraciones (p. ej., 1, 2, 4, 8 procesos) y mide cómo afecta al tiempo de ejecución del proceso de MapReduce.\n",
    "Resultados esperados: Documentar cómo el incremento en el número de procesos afecta la eficiencia del procesamiento, identificando el punto de saturación donde más procesos no resultan en mejoras significativas.\n",
    "\n",
    "#### Ejercicio 2: Comparación con threads\n",
    "\n",
    "Implementa una versión del proceso de MapReduce usando concurrent.futures.ThreadPoolExecutor en lugar de multiprocessing.Pool y compara el rendimiento con la versión actual que utiliza procesos.\n",
    "Resultados esperados: Observar las diferencias en rendimiento y cómo el GIL afecta la versión que utiliza hilos, especialmente cuando se incrementa el número de hilos.\n",
    "\n",
    "#### Ejercicio 3: Análisis de granularidad de los datos\n",
    "Experimenta con una gama más amplia de tamaños de fragmentos para entender mejor cómo la granularidad de los datos influye en el rendimiento del sistema. Considera extremos más variados y tamaños intermedios.\n",
    "Resultados esperados: Identificar un tamaño óptimo de fragmento que maximice la eficiencia del procesamiento, y explicar por qué ciertos tamaños resultan menos eficientes.\n",
    "\n",
    "#### Ejercicio 4: Implementación de funciones de MapReduce más complejas\n",
    "Crea funciones de mapeo y reducción más complejas que simulen cargas de trabajo más intensivas, como procesamiento de texto o cálculos matemáticos.\n",
    "Resultados esperados: Observar cómo el aumento de la complejidad de las tareas afecta el rendimiento y cómo se puede ajustar el tamaño del pool y de los fragmentos para optimizar el procesamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ac8327-c058-4906-babc-6ef034356a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad7252f-ae5b-4324-8adc-7e5800d0504a",
   "metadata": {},
   "source": [
    "### Parte 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39306c2a-11cc-4029-8514-228a87ed7271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import marshal\n",
    "import pickle\n",
    "import socket\n",
    "from time import sleep\n",
    "# Codigo de Tiago Rodriguez\n",
    "\n",
    "def my_funs():\n",
    "    def mapper(v):\n",
    "        return v, 1 \n",
    "\n",
    "    def reducer(my_args):\n",
    "        v, obs = my_args\n",
    "        return v, sum(obs)\n",
    "    return mapper, reducer\n",
    "\n",
    "\n",
    "def do_request(my_funs, data):\n",
    "    conn = socket.create_connection(('127.0.0.1', 1936))\n",
    "    conn.send(b'\\x00')\n",
    "    my_code = marshal.dumps(my_funs.__code__)\n",
    "    conn.send(len(my_code).to_bytes(4, 'little', signed=False))\n",
    "    conn.send(my_code)\n",
    "    my_data = pickle.dumps(data)\n",
    "    conn.send(len(my_data).to_bytes(4, 'little'))\n",
    "    conn.send(my_data)\n",
    "    job_id = int.from_bytes(conn.recv(4), 'little')\n",
    "    conn.close()\n",
    "\n",
    "    print(f'Obtener data desde job_id {job_id}')\n",
    "    result = None\n",
    "    while result is None:\n",
    "        conn = socket.create_connection(('127.0.0.1', 1936))\n",
    "        conn.send(b'\\x01')\n",
    "        conn.send(job_id.to_bytes(4, 'little'))\n",
    "        result_size = int.from_bytes(conn.recv(4), 'little')\n",
    "        result = pickle.loads(conn.recv(result_size))\n",
    "        conn.close()\n",
    "        sleep(1)\n",
    "    print(f'Resultado es {result}')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    do_request(my_funs, 'Python rocks. Python es divertido'.split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89acf8c3-6cd4-43c2-980b-358542c7c925",
   "metadata": {},
   "source": [
    "- marshal: Se utiliza para serializar el objeto del código fuente de las funciones.\n",
    "- pickle: Se utiliza para serializar los datos que se envían a través de los sockets.\n",
    "- socket: Se utiliza para crear conexiones de red y enviar datos.\n",
    "- sleep de time: Se utiliza para pausar la ejecución durante un segundo antes de volver a intentar obtener el resultado del trabajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c4fb12-00a2-4204-a0be-ac2bed489d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_funs():\n",
    "    def mapper(v):\n",
    "        return v, 1 \n",
    "\n",
    "    def reducer(my_args):\n",
    "        v, obs = my_args\n",
    "        return v, sum(obs)\n",
    "    return mapper, reducer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b841eef0-af6a-4c44-8188-2c48dc2e23d4",
   "metadata": {},
   "source": [
    "- Esta función define dos funciones internas: mapper y reducer.\n",
    "- La función mapper toma un valor v y devuelve una tupla con v como la clave y 1 como el valor.\n",
    "- La función reducer toma una tupla de argumentos (v, obs) y devuelve una tupla con v como la clave y la suma de los valores en obs.\n",
    "- Ambas funciones son funciones simples de mapeo y reducción que serán utilizadas en el proceso de MapReduce.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2bc7a9-8ab9-4dbb-9941-a1638784c001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_request(my_funs, data):\n",
    "    conn = socket.create_connection(('127.0.0.1', 1936))\n",
    "    conn.send(b'\\x00')\n",
    "    my_code = marshal.dumps(my_funs.__code__)\n",
    "    conn.send(len(my_code).to_bytes(4, 'little', signed=False))\n",
    "    conn.send(my_code)\n",
    "    my_data = pickle.dumps(data)\n",
    "    conn.send(len(my_data).to_bytes(4, 'little'))\n",
    "    conn.send(my_data)\n",
    "    job_id = int.from_bytes(conn.recv(4), 'little')\n",
    "    conn.close()\n",
    "\n",
    "    print(f'Obtener data desde job_id {job_id}')\n",
    "    result = None\n",
    "    while result is None:\n",
    "        conn = socket.create_connection(('127.0.0.1', 1936))\n",
    "        conn.send(b'\\x01')\n",
    "        conn.send(job_id.to_bytes(4, 'little'))\n",
    "        result_size = int.from_bytes(conn.recv(4), 'little')\n",
    "        result = pickle.loads(conn.recv(result_size))\n",
    "        conn.close()\n",
    "        sleep(1)\n",
    "    print(f'Resultado es {result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650a28ed-b1ab-41e8-922e-40477ed65a0f",
   "metadata": {},
   "source": [
    "- Esta función realiza la comunicación con un servidor remoto para enviar las funciones my_funs y los datos data para procesamiento.\n",
    "- Se crea una conexión a un servidor en el puerto 1936 en localhost (127.0.0.1).\n",
    "- Se envía un byte b'\\x00' para indicar que se enviarán las funciones.\n",
    "- Se serializa el objeto de código de las funciones my_funs utilizando marshal y se envía su longitud y contenido a través del socket.\n",
    "- Los datos data se serializan usando pickle y se envían también con su longitud.\n",
    "- Se recibe un ID de trabajo (job_id) del servidor, que se utilizará para recuperar el resultado más tarde.\n",
    "- La función espera un segundo antes de intentar obtener el resultado.\n",
    "- Se crea una nueva conexión para solicitar el resultado del trabajo.\n",
    "- Se envía un byte b'\\x01' para indicar que se solicita el resultado.\n",
    "- Se envía el job_id y se espera a recibir el tamaño del resultado.\n",
    "- Se recibe el resultado serializado y se deserializa usando pickle.\n",
    "- El resultado se imprime cuando está disponible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a104f9bf-e22f-41ed-a0ae-fb858d9fd635",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import marshal\n",
    "import multiprocessing as mp\n",
    "import pickle\n",
    "from queue import Empty, Queue  # PriorityQueue\n",
    "import threading\n",
    "import types\n",
    "\n",
    "import chunk_mp_mapreduce as mr\n",
    "\n",
    "\n",
    "# multiprocessing.Queue\n",
    "\n",
    "work_queue = Queue()\n",
    "results_queue = Queue()\n",
    "results = {}\n",
    "\n",
    "async def submit_job(job_id, reader, writer):\n",
    "    writer.write(job_id.to_bytes(4, 'little'))\n",
    "    writer.close()\n",
    "    code_size = int.from_bytes(await reader.read(4), 'little')\n",
    "    my_code = marshal.loads(await reader.read(code_size))\n",
    "    data_size = int.from_bytes(await reader.read(4), 'little')\n",
    "    data = pickle.loads(await reader.read(data_size))\n",
    "    work_queue.put_nowait((job_id, my_code, data))  \n",
    "\n",
    "\n",
    "def get_results_queue():\n",
    "    while results_queue.qsize() > 0: \n",
    "        try:\n",
    "            job_id, data = results_queue.get_nowait()\n",
    "            results[job_id] = data\n",
    "        except Empty:\n",
    "            return\n",
    "\n",
    "\n",
    "async def get_results(reader, writer):\n",
    "    get_results_queue()\n",
    "    job_id = int.from_bytes(await reader.read(4), 'little')\n",
    "    data = pickle.dumps(None)\n",
    "    if job_id in results:\n",
    "        data = pickle.dumps(results[job_id])\n",
    "        del results[job_id]\n",
    "    writer.write(len(data).to_bytes(4, 'little'))\n",
    "    writer.write(data)\n",
    "\n",
    "\n",
    "async def accept_requests(reader, writer, job_id=[0]):\n",
    "    op = await reader.read(1)\n",
    "    if op[0] == 0:\n",
    "        await submit_job(job_id[0], reader, writer)  #Errors in async\n",
    "        job_id[0] += 1\n",
    "    elif op[0] == 1:\n",
    "        await get_results(reader, writer)\n",
    "\n",
    "\n",
    "def worker():  # daemon\n",
    "    pool = mp.Pool()\n",
    "    while True:\n",
    "        job_id, code, data = work_queue.get()  # blocking\n",
    "        func = types.FunctionType(code, globals(), 'mapper_and_reducer')\n",
    "        mapper, reducer = func()\n",
    "        counts = mr.map_reduce(pool, data, mapper, reducer, 100, mr.reporter)\n",
    "        results_queue.put((job_id, counts))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "\n",
    "async def main():\n",
    "    server = await asyncio.start_server(accept_requests, '127.0.0.1', 1936)\n",
    "    worker_thread = threading.Thread(target=worker)   # Daemon\n",
    "    worker_thread.start()\n",
    "    async with server:\n",
    "        await server.serve_forever()\n",
    "\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1d5f42-90c7-4b4d-b406-4f5fa7358c2f",
   "metadata": {},
   "source": [
    "Este código implementa un sistema de MapReduce distribuido utilizando asyncio y multiprocessing en Python. Puedes explicar el funcionamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6920a31b-91df-45ac-9ba3-9beb54f3497a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c26a36-64eb-421b-862e-1883b03639d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import marshal\n",
    "import multiprocessing as mp\n",
    "import sys\n",
    "from time import sleep\n",
    "import types\n",
    "\n",
    "# Función para monitorear el progreso de tareas asincrónicas en el pool de procesos\n",
    "def report_progress(map_returns, tag, callback):\n",
    "    done = 0\n",
    "    num_jobs = len(map_returns)  # Cantidad total de tareas\n",
    "    while num_jobs > done:\n",
    "        done = 0  # Reinicia el contador de tareas completadas en cada iteración\n",
    "        for ret in map_returns:  # Revisa cada tarea en el conjunto de resultados\n",
    "            if ret.ready():  # Verifica si la tarea está completa\n",
    "                done += 1\n",
    "        sleep(0.5)  # Espera antes de la próxima revisión para reducir carga del CPU\n",
    "        if callback:  # Si existe un callback, reporta el progreso\n",
    "            callback(tag, done, num_jobs - done)\n",
    "\n",
    "# Función para dividir una lista en fragmentos de tamaño especificado\n",
    "def chunk0(my_list, chunk_size):\n",
    "    for i in range(0, len(my_list), chunk_size):\n",
    "        yield my_list[i:i + chunk_size]\n",
    "\n",
    "# Función para dividir cualquier iterable en fragmentos de tamaño especificado\n",
    "def chunk(my_iter, chunk_size):\n",
    "    chunk_list = []\n",
    "    for elem in my_iter:\n",
    "        chunk_list.append(elem)\n",
    "        if len(chunk_list) == chunk_size:\n",
    "            yield chunk_list\n",
    "            chunk_list = []\n",
    "    if len(chunk_list) > 0:\n",
    "        yield chunk_list\n",
    "\n",
    "# Función que ejecuta una función sobre un conjunto de datos; la función es pasada como código serializado\n",
    "def chunk_runner(fun_marshal, data):\n",
    "    # Deserializa el código de función y lo convierte en una función ejecutable\n",
    "    fun = types.FunctionType(marshal.loads(fun_marshal), globals(), 'fun')\n",
    "    ret = []\n",
    "    for datum in data:\n",
    "        print(fun(datum))  # Opcional: imprimir cada resultado para depuración\n",
    "        ret.append(fun(datum))  # Aplica la función y almacena el resultado\n",
    "    return ret\n",
    "\n",
    "# Función para aplicar map de manera asincrónica utilizando un pool de procesos\n",
    "def chunked_async_map(pool, mapper, data, chunk_size):\n",
    "    async_returns = []\n",
    "    for data_part in chunk(data, chunk_size):\n",
    "        # Empaqueta cada función y datos y los envía al pool\n",
    "        async_returns.append(pool.apply_async(chunk_runner, (marshal.dumps(mapper.__code__), data_part)))\n",
    "    return async_returns\n",
    "\n",
    "# Función principal de MapReduce\n",
    "def map_reduce(pool, my_input, mapper, reducer, chunk_size, callback=None): \n",
    "    # Mapeo: Aplica la función mapper a los datos de entrada\n",
    "    map_returns = chunked_async_map(pool, mapper, my_input, chunk_size)\n",
    "    report_progress(map_returns, 'map', callback)\n",
    "    map_results = []\n",
    "    for ret in map_returns:\n",
    "        map_results.extend(ret.get())  # Recopila todos los resultados del mapeo\n",
    "\n",
    "    # Agrupa los resultados del mapeo por clave\n",
    "    distributor = defaultdict(list)\n",
    "    for key, value in map_results:\n",
    "        distributor[key].append(value)\n",
    "\n",
    "    # Reducción: Aplica la función reducer a los resultados agrupados\n",
    "    returns = chunked_async_map(pool, reducer, distributor.items(), chunk_size)\n",
    "    report_progress(returns, 'reduce', callback)\n",
    "    results = []\n",
    "    for ret in returns:\n",
    "        results.extend(ret.get())  # Recopila todos los resultados de la reducción\n",
    "    return results\n",
    "\n",
    "# Función para emitir cada palabra con un conteo inicial de 1\n",
    "def emitter(word):\n",
    "    return word, 1\n",
    "\n",
    "# Función para sumar conteos de cada palabra\n",
    "def counter(emitted):\n",
    "    return emitted[0], sum(emitted[1])\n",
    "\n",
    "# Función callback para imprimir el progreso de la operación\n",
    "def reporter(tag, done, not_done):\n",
    "    print(f'Operacion {tag}: {done}/{done+not_done}')\n",
    "\n",
    "# Ejecución del código\n",
    "words = 'Python es super, Python rocks'.split(' ')\n",
    "pool = mp.Pool()  # Crea un pool de procesos\n",
    "results = map_reduce(pool, words, emitter, counter, 10, reporter)\n",
    "pool.close()  # Cierra el pool\n",
    "pool.join()  # Espera que todos los procesos terminen\n",
    "\n",
    "# Imprime resultados finales\n",
    "for result in sorted(results, key=lambda x: x[1]):\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6f3d0d-71b6-4c82-976c-8cd18b47e9d3",
   "metadata": {},
   "source": [
    "\n",
    "El código proporcionado implementa una versión avanzada del patrón MapReduce utilizando multiprocessing, manejo de datos en segmentos (chunks), y serialización de funciones para permitir su ejecución en un entorno multiproceso. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e536e5e7-6ca9-4a88-bc31-94911270d3c4",
   "metadata": {},
   "source": [
    "#### Ejercicio 1: Sistema de análisis de datos distribuido\n",
    "Implementa un sistema distribuido para analizar datos enviados a un servidor centralizado utilizando técnicas de MapReduce y serialización de funciones.\n",
    "\n",
    "Descripción:\n",
    "- Modifica el código para soportar la ejecución de diferentes análisis estadísticos (media, mediana, moda) que los clientes pueden solicitar dinámicamente.\n",
    "- Implementa una funcionalidad en el servidor para recibir funciones de análisis como entrada, serializadas desde el cliente, ejecutarlas y devolver los resultados.\n",
    "- Asegúrate de que el sistema pueda manejar múltiples solicitudes de análisis simultáneamente utilizando multiprocessing.\n",
    "\n",
    "#### Ejercicio 2: Servicio de procesamiento de consultas en tiempo real\n",
    "Crea un servicio que procese consultas en tiempo real sobre un conjunto de datos compartido, utilizando un modelo distribuido y asyncio para la gestión de consultas.\n",
    "\n",
    "Descripción:\n",
    "- Utiliza sockets para permitir que múltiples clientes envíen consultas que incluyan funciones de procesamiento de datos serializadas.\n",
    "- Desarrolla un sistema de cola de trabajo donde las consultas se distribuyan entre varios procesadores utilizando multiprocessing.\n",
    "- Implementa lógica para manejar consultas concurrentes y asegurar que los resultados se devuelvan de manera asincrónica a los clientes apropiados.\n",
    "\n",
    "#### Ejercicio 3: Sistema de ejecución de tareas asincrónicas programables\n",
    "\n",
    "Construye un sistema que permita a los usuarios definir tareas programables que se ejecuten en el servidor, utilizando una combinación de asyncio y multiprocessing.\n",
    "\n",
    "Descripción:\n",
    "- Configura un servidor que pueda recibir definiciones de tareas (funciones y datos) serializadas de los clientes.\n",
    "- Las tareas deben ser planificadas y ejecutadas en paralelo utilizando un pool de procesos.\n",
    "- Utiliza asyncio para gestionar la comunicación entre el cliente y el servidor, asegurando que las respuestas se envíen de vuelta a los clientes tan pronto como las tareas se completen.\n",
    "\n",
    "#### Ejercicio 4: Sistema de monitoreo de red distribuido\n",
    "Desarrolla un sistema para monitorear el estado de múltiples servidores en una red, recopilando datos de manera asincrónica y procesándolos en paralelo.\n",
    "\n",
    "Descripción:\n",
    "- Implementa un servidor central que recibe datos serializados de estado desde múltiples nodos cliente.\n",
    "- Los datos pueden incluir métricas como CPU, memoria, uso de disco, etc., y deben ser procesados utilizando funciones MapReduce para generar informes de salud del sistema.\n",
    "- Utiliza asyncio para manejar las solicitudes de los nodos de manera asincrónica y multiprocessing para el procesamiento en paralelo de los datos recogidos.\n",
    "\n",
    "#### Ejercicio 5: Plataforma de pruebas A/B distribuida\n",
    "Crea una plataforma que realice pruebas A/B en tiempo real sobre datos de usuario recogidos de diferentes ubicaciones, utilizando técnicas de procesamiento distribuido.\n",
    "\n",
    "Descripción:\n",
    "- Configura un sistema que reciba datos de experimentos A/B de clientes a través de la red, utilizando socket.\n",
    "- Serializa lógica de análisis y envíala a un servidor que utilice multiprocessing para evaluar los resultados de las pruebas A/B en paralelo.\n",
    "- Emplea asyncio para responder a las solicitudes de análisis, devolviendo resultados basados en el análisis de datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcde2c9-ffa3-44cd-960f-9192f3a044e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tus respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1df7414-2f21-410d-ac6c-d1d47c5557ae",
   "metadata": {},
   "source": [
    "### Entregable\n",
    "\n",
    "Presente este cuaderno desarrollado en tu repositorio personal."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
